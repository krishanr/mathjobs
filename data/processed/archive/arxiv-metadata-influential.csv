year,id,references,title,abstract,authors,journal-ref,group_name,group_name_uq
1993,hep-th/9209055,25,Quantum Aspects of Black Holes,"  This review is based on lectures given at the 1992 Trieste Spring School on
String Theory and Quantum Gravity and at the 1992 TASI Summer School in
Boulder, Colorado.
",J. A. Harvey and A. Strominger,,Physics,Physics
1993,hep-th/9304011,16,Lectures on 2D gravity and 2D string theory (TASI 1992),"  Emphasis is on 2d target space (c=1 coupled to gravity).
  Contents:
  0. Introduction, Overview, and Purpose
  1. Loops and States in Conformal Field Theory
  2. 2D Euclidean Quantum Gravity I: Path Integral Approach
  3. Brief Review of the Liouville Theory
  4. 2D Euclidean Quantum Gravity II: Canonical Approach
  5. 2D Critical String Theory
  6. Discretized surfaces, matrix models, and the continuum limit
  7. Matrix Model Technology I: Method of Orthogonal Polynomials
  8. Matrix Model Technology II: Loops on the Lattice
  9. Matrix Model Technology III: Free Fermions from the Lattice
  10. Loops and States in Matrix Model Quantum Gravity
  11. Loops and States in the $c=1$ Matrix Model
  12. Fermi Sea Dynamics and Collective Field Theory
  13. String scattering in two spacetime dimensions
  14. Vertex Operator Calculations and Continuum Methods
  15. Achievements, Disappointments, Future Prospects
  ""if you read only one set of lecture notes this year, don't read these.""
",P. Ginsparg and Gregory Moore,,Physics,Physics
1993,hep-th/9211030,15,Black Hole Remnants and the Information Puzzle,"  Magnetically charged dilatonic black holes have a perturbatively infinite
ground state degeneracy associated with an infinite volume throat region of the
geometry. A simple argument based on causality is given that these states do
not have a description as ordinary massive particles in a low-energy effective
field theory. Pair production of magnetic black holes in a weak magnetic field
is estimated in a weakly-coupled semiclassical expansion about an instanton and
found to be finite, despite the infinite degeneracy of states. This suggests
that these states may store the information apparently lost in black hole
scattering processes.
","T. Banks, M. O'Loughlin, and A. Strominger","Phys.Rev.D47:4476-4482,1993",Physics,Physics
1994,hep-th/9309145,24,Some Speculations about Black Hole Entropy in String Theory,"  The classical Bekenstein entropy of a black hole is argued to arise from
configurations of strings with ends which are frozen on the horizon. Quantum
corrections to this entropy are probably finite unlike the case in quantum
field theory. Finally it is speculated that all black holes are single string
states. The level density of strings is of the right order of magnitude to
reproduce the Bekenstein entropy.
",Leonard Susskind,,Physics,Physics
1994,hep-th/9401139,23,Target Space Duality in String Theory,"  A review article submitted to Physics Report: Target space duality and
discrete symmetries in string theory are reviewed in different settings.
","A. Giveon, M. Porrati and E. Rabinovici","Phys.Rept.244:77-202,1994",Physics,Physics
1994,hep-th/9402002,22,Strong-Weak Coupling Duality in Four Dimensional String Theory,"  We present several pieces of evidence for strong-weak coupling duality
symmetry in the heterotic string theory, compactified on a six dimensional
torus. These include symmetry of the 1) low energy effective action, 2) allowed
spectrum of electric and magnetic charges in the theory, 3) allowed mass
spectrum of particles saturating the Bogomol'nyi bound, and 4) Yukawa couplings
between massless neutral particles and massive charged particles saturating the
Bogomol'nyi bound. This duality transformation exchanges the electrically
charged elementary string excitations with the magnetically charged soliton
states in the theory. It is shown that the existence of a strong-weak coupling
duality symmetry in four dimensional string theory makes definite prediction
about the existence of new stable monopole and dyon states in the theory with
specific degeneracies, including certain supersymmetric bound states of
monopoles and dyons. The relationship between strong-weak coupling duality
transformation in string theory and target space duality transformation in the
five-brane theory is also discussed. (Based on a talk given at the workshop on
Strings and Gravity, Madras, India.)
",Ashoke Sen,"Int.J.Mod.Phys.A9:3707-3750,1994",Physics,Physics
1995,hep-th/9503124,84,String Theory Dynamics In Various Dimensions,"  The strong coupling dynamics of string theories in dimension $d\geq 4$ are
studied. It is argued, among other things, that eleven-dimensional supergravity
arises as a low energy limit of the ten-dimensional Type IIA superstring, and
that a recently conjectured duality between the heterotic string and Type IIA
superstrings controls the strong coupling dynamics of the heterotic string in
five, six, and seven dimensions and implies $S$ duality for both heterotic and
Type II strings.
",Edward Witten,"Nucl.Phys.B443:85-126,1995",Physics,Physics
1997,hep-th/9503124,153,String Theory Dynamics In Various Dimensions,"  The strong coupling dynamics of string theories in dimension $d\geq 4$ are
studied. It is argued, among other things, that eleven-dimensional supergravity
arises as a low energy limit of the ten-dimensional Type IIA superstring, and
that a recently conjectured duality between the heterotic string and Type IIA
superstrings controls the strong coupling dynamics of the heterotic string in
five, six, and seven dimensions and implies $S$ duality for both heterotic and
Type II strings.
",Edward Witten,"Nucl.Phys.B443:85-126,1995",Physics,Physics
1995,hep-th/9410167,72,Unity of Superstring Dualities,"  The effective action for type II string theory compactified on a six torus is
$N=8$ supergravity, which is known to have an $E_{7}$ duality symmetry. We show
that this is broken by quantum effects to a discrete subgroup, $E_7(\Z)$, which
contains both the T-duality group $SO(6,6;\Z)$ and the S-duality group
$SL(2;\Z)$. We present evidence for the conjecture that $E_7(\Z)$ is an exact
\lq U-duality' symmetry of type II string theory. This conjecture requires
certain extreme black hole states to be identified with massive modes of the
fundamental string. The gauge bosons from the Ramond-Ramond sector couple not
to string excitations but to solitons. We discuss similar issues in the context
of toroidal string compactifications to other dimensions, compactifications of
the type II string on $K_3\times T^2$ and compactifications of
eleven-dimensional supermembrane theory.
",C. M. Hull and P. K. Townsend,"Nucl.Phys.B438:109-137,1995",Physics,Physics
1995,hep-th/9407087,67,"Monopole Condensation, And Confinement In N=2 Supersymmetric Yang-Mills
  Theory","  We study the vacuum structure and dyon spectrum of N=2 supersymmetric gauge
theory in four dimensions, with gauge group SU(2). The theory turns out to have
remarkably rich and physical properties which can nonetheless be described
precisely; exact formulas can be obtained, for instance, for electron and dyon
masses and the metric on the moduli space of vacua. The description involves a
version of Olive-Montonen electric-magnetic duality. The ``strongly coupled''
vacuum turns out to be a weakly coupled theory of monopoles, and with a
suitable perturbation confinement is described by monopole condensation.
",N. Seiberg and E. Witten,"Nucl.Phys.B426:19-52,1994; Erratum-ibid.B430:485-486,1994",Physics,Physics
1996,hep-th/9602052,157,Notes on D-Branes,"  This is a series of remedial lectures on open and unoriented strings for the
heterotic string generation. The particular focus is on the interesting
features that arise under T-duality---D-branes and orientifolds. The final
lecture discusses the application to string duality. There will be no puns.
Lectures presented by J. P. at the ITP from Nov. 16 to Dec. 5, 1995. References
updated through Jan. 25, 1996.
","Joseph Polchinski, Shyamoli Chaudhuri, Clifford V. Johnson",,Physics,Physics
1996,hep-th/9510017,136,Dirichlet-Branes and Ramond-Ramond Charges,"  We show that Dirichlet-branes, extended objects defined by mixed
Dirichlet-Neumann boundary conditions in string theory, break half of the
supersymmetries of the type~II superstring and carry a complete set of electric
and magnetic Ramond-Ramond charges. We also find that the product of the
electric and magnetic charges is a single Dirac unit, and that the quantum of
charge takes the value required by string duality. This is strong evidence that
the Dirchlet-branes are intrinsic to type II string theory and are the
Ramond-Ramond sources required by string duality. We also note the existence of
a previously overlooked 9-form potential in the IIa string, which gives rise to
an effective cosmological constant of undetermined magnitude.
",Joseph Polchinski,"Phys.Rev.Lett.75:4724-4727,1995",Physics,Physics
1996,hep-th/9601029,128,Microscopic Origin of the Bekenstein-Hawking Entropy,"  The Bekenstein-Hawking area-entropy relation $S_{BH}=A/4$ is derived for a
class of five-dimensional extremal black holes in string theory by counting the
degeneracy of BPS soliton bound states.
",A. Strominger and C. Vafa,"Phys.Lett.B379:99-104,1996",Physics,Physics
1997,hep-th/9610043,280,M Theory As A Matrix Model: A Conjecture,"  We suggest and motivate a precise equivalence between uncompactified eleven
dimensional M-theory and the N = infinity limit of the supersymmetric matrix
quantum mechanics describing D0-branes. The evidence for the conjecture
consists of several correspondences between the two theories. As a consequence
of supersymmetry the simple matrix model is rich enough to describe the
properties of the entire Fock space of massless well separated particles of the
supergravity theory. In one particular kinematic situation the leading large
distance interaction of these particles is exactly described by supergravity .
The model appears to be a nonperturbative realization of the holographic
principle. The membrane states required by M-theory are contained as
excitations of the matrix model. The membrane world volume is a noncommutative
geometry embedded in a noncommutative spacetime.
","T. Banks, W. Fischler, S.H. Shenker, L. Susskind","Phys.Rev.D55:5112-5128,1997",Physics,Physics
1997,hep-th/9611050,232,TASI Lectures on D-Branes,"  This is an introduction to the properties of D-branes, topological defects in
string theory on which string endpoints can live. D-branes provide a simple
description of various nonperturbative objects required by string duality, and
give new insight into the quantum mechanics of black holes and the nature of
spacetime at the shortest distances. The first two thirds of these lectures
closely follow the earlier ITP lectures hep-th/9602052, written with S.
Chaudhuri and C. Johnson. The final third includes more extensive applications
to string duality.
",Joseph Polchinski,,Physics,Physics
1998,hep-th/9711200,440,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
1999,hep-th/9711200,483,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2000,hep-th/9711200,342,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2001,hep-th/9711200,281,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2002,hep-th/9711200,368,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2003,hep-th/9711200,302,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2004,hep-th/9711200,369,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2005,hep-th/9711200,332,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2006,hep-th/9711200,430,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2007,hep-th/9711200,485,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2008,hep-th/9711200,562,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2009,hep-th/9711200,572,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2010,hep-th/9711200,575,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2011,hep-th/9711200,572,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2012,hep-th/9711200,534,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2016,hep-th/9711200,537,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2017,hep-th/9711200,492,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2018,hep-th/9711200,543,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
2019,hep-th/9711200,551,The Large N Limit of Superconformal Field Theories and Supergravity,"  We show that the large $N$ limit of certain conformal field theories in
various dimensions include in their Hilbert space a sector describing
supergravity on the product of Anti-deSitter spacetimes, spheres and other
compact manifolds. This is shown by taking some branes in the full M/string
theory and then taking a low energy limit where the field theory on the brane
decouples from the bulk. We observe that, in this limit, we can still trust the
near horizon geometry for large $N$. The enhanced supersymmetries of the near
horizon geometry correspond to the extra supersymmetry generators present in
the superconformal group (as opposed to just the super-Poincare group). The 't
Hooft limit of 4-d ${\cal N} =4$ super-Yang-Mills at the conformal point is
shown to contain strings: they are IIB strings. We conjecture that
compactifications of M/string theory on various Anti-deSitter spacetimes are
dual to various conformal field theories. This leads to a new proposal for a
definition of M-theory which could be extended to include five non-compact
dimensions.
",Juan M. Maldacena,"Adv.Theor.Math.Phys.2:231-252,1998",Physics,Physics
1998,hep-th/9802150,346,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
1999,hep-th/9802150,358,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2002,hep-th/9802150,273,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2005,hep-th/9802150,226,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2006,hep-th/9802150,297,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2007,hep-th/9802150,319,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2008,hep-th/9802150,377,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2009,hep-th/9802150,366,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2010,hep-th/9802150,393,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
2011,hep-th/9802150,384,Anti De Sitter Space And Holography,"  Recently, it has been proposed by Maldacena that large $N$ limits of certain
conformal field theories in $d$ dimensions can be described in terms of
supergravity (and string theory) on the product of $d+1$-dimensional $AdS$
space with a compact manifold. Here we elaborate on this idea and propose a
precise correspondence between conformal field theory observables and those of
supergravity: correlation functions in conformal field theory are given by the
dependence of the supergravity action on the asymptotic behavior at infinity.
In particular, dimensions of operators in conformal field theory are given by
masses of particles in supergravity. As quantitative confirmation of this
correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on
$AdS_5\times {\bf S}^5$ match with the chiral operators of $\N=4$ super
Yang-Mills theory in four dimensions. With some further assumptions, one can
deduce a Hamiltonian version of the correspondence and show that the $\N=4$
theory has a large $N$ phase transition related to the thermodynamics of $AdS$
black holes.
",Edward Witten,"Adv.Theor.Math.Phys.2:253-291,1998",Physics,Physics
1998,hep-th/9802109,300,Gauge Theory Correlators from Non-Critical String Theory,"  We suggest a means of obtaining certain Green's functions in 3+1-dimensional
${\cal N} = 4$ supersymmetric Yang-Mills theory with a large number of colors
via non-critical string theory. The non-critical string theory is related to
critical string theory in anti-deSitter background. We introduce a boundary of
the anti-deSitter space analogous to a cut-off on the Liouville coordinate of
the two-dimensional string theory. Correlation functions of operators in the
gauge theory are related to the dependence of the supergravity action on the
boundary conditions. From the quadratic terms in supergravity we read off the
anomalous dimensions. For operators that couple to massless string states it
has been established through absorption calculations that the anomalous
dimensions vanish, and we rederive this result. The operators that couple to
massive string states at level $n$ acquire anomalous dimensions that grow as
$2\left (n g_{YM} \sqrt {2 N} )^{1/2}$ for large `t Hooft coupling. This is a
new prediction about the strong coupling behavior of large $N$ SYM theory.
","S.S. Gubser, I.R. Klebanov and A.M. Polyakov","Phys.Lett.B428:105-114,1998",Physics,Physics
1999,hep-th/9802109,335,Gauge Theory Correlators from Non-Critical String Theory,"  We suggest a means of obtaining certain Green's functions in 3+1-dimensional
${\cal N} = 4$ supersymmetric Yang-Mills theory with a large number of colors
via non-critical string theory. The non-critical string theory is related to
critical string theory in anti-deSitter background. We introduce a boundary of
the anti-deSitter space analogous to a cut-off on the Liouville coordinate of
the two-dimensional string theory. Correlation functions of operators in the
gauge theory are related to the dependence of the supergravity action on the
boundary conditions. From the quadratic terms in supergravity we read off the
anomalous dimensions. For operators that couple to massless string states it
has been established through absorption calculations that the anomalous
dimensions vanish, and we rederive this result. The operators that couple to
massive string states at level $n$ acquire anomalous dimensions that grow as
$2\left (n g_{YM} \sqrt {2 N} )^{1/2}$ for large `t Hooft coupling. This is a
new prediction about the strong coupling behavior of large $N$ SYM theory.
","S.S. Gubser, I.R. Klebanov and A.M. Polyakov","Phys.Lett.B428:105-114,1998",Physics,Physics
2000,hep-th/9908142,259,String Theory and Noncommutative Geometry,"  We extend earlier ideas about the appearance of noncommutative geometry in
string theory with a nonzero B-field. We identify a limit in which the entire
string dynamics is described by a minimally coupled (supersymmetric) gauge
theory on a noncommutative space, and discuss the corrections away from this
limit. Our analysis leads us to an equivalence between ordinary gauge fields
and noncommutative gauge fields, which is realized by a change of variables
that can be described explicitly. This change of variables is checked by
comparing the ordinary Dirac-Born-Infeld theory with its noncommutative
counterpart. We obtain a new perspective on noncommutative gauge theory on a
torus, its T-duality, and Morita equivalence. We also discuss the D0/D4 system,
the relation to M-theory in DLCQ, and a possible noncommutative version of the
six-dimensional (2,0) theory.
",Nathan Seiberg and Edward Witten,"JHEP 9909:032,1999",Physics,"Physics,Mathematics"
2001,hep-th/9908142,275,String Theory and Noncommutative Geometry,"  We extend earlier ideas about the appearance of noncommutative geometry in
string theory with a nonzero B-field. We identify a limit in which the entire
string dynamics is described by a minimally coupled (supersymmetric) gauge
theory on a noncommutative space, and discuss the corrections away from this
limit. Our analysis leads us to an equivalence between ordinary gauge fields
and noncommutative gauge fields, which is realized by a change of variables
that can be described explicitly. This change of variables is checked by
comparing the ordinary Dirac-Born-Infeld theory with its noncommutative
counterpart. We obtain a new perspective on noncommutative gauge theory on a
torus, its T-duality, and Morita equivalence. We also discuss the D0/D4 system,
the relation to M-theory in DLCQ, and a possible noncommutative version of the
six-dimensional (2,0) theory.
",Nathan Seiberg and Edward Witten,"JHEP 9909:032,1999",Physics,"Physics,Mathematics"
2000,hep-th/9906064,246,An Alternative to Compactification,"  Conventional wisdom states that Newton's force law implies only four
non-compact dimensions. We demonstrate that this is not necessarily true in the
presence of a non-factorizable background geometry. The specific example we
study is a single 3-brane embedded in five dimensions. We show that even
without a gap in the Kaluza-Klein spectrum, four-dimensional Newtonian and
general relativistic gravity is reproduced to more than adequate precision.
","Lisa Randall, Raman Sundrum","Phys.Rev.Lett.83:4690-4693,1999",Physics,Physics
2001,hep-th/9906064,250,An Alternative to Compactification,"  Conventional wisdom states that Newton's force law implies only four
non-compact dimensions. We demonstrate that this is not necessarily true in the
presence of a non-factorizable background geometry. The specific example we
study is a single 3-brane embedded in five dimensions. We show that even
without a gap in the Kaluza-Klein spectrum, four-dimensional Newtonian and
general relativistic gravity is reproduced to more than adequate precision.
","Lisa Randall, Raman Sundrum","Phys.Rev.Lett.83:4690-4693,1999",Physics,Physics
2002,hep-th/0202021,260,Strings in flat space and pp waves from ${\cal N}=4$ Super Yang Mills,"  We explain how the string spectrum in flat space and pp-waves arises from the
large $N$ limit, at fixed $g^2_{YM}$, of U(N) ${\cal N} =4$ super Yang Mills.
We reproduce the spectrum by summing a subset of the planar Feynman diagrams.
We give a heuristic argument for why we can neglect other diagrams. We also
discuss some other aspects of pp-waves and we present a matrix model associated
to the DLCQ description of the maximally supersymmetric eleven dimensional
pp-waves.
","David Berenstein, Juan Maldacena and Horatiu Nastase",JHEP 0204 (2002) 013,Physics,Physics
2003,astro-ph/0302209,362,"First Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Determination of Cosmological Parameters","  WMAP precision data enables accurate testing of cosmological models. We find
that the emerging standard model of cosmology, a flat Lambda-dominated universe
seeded by nearly scale-invariant adiabatic Gaussian fluctuations, fits the WMAP
data. With parameters fixed only by WMAP data, we can fit finer scale CMB
measurements and measurements of large scle structure (galaxy surveys and the
Lyman alpha forest). This simple model is also consistent with a host of other
astronomical measurements. We then fit the model parameters to a combination of
WMAP data with other finer scale CMB experiments (ACBAR and CBI), 2dFGRS
measurements and Lyman alpha forest data to find the model's best fit
cosmological parameters: h=0.71+0.04-0.03, Omega_b h^2=0.0224+-0.0009, Omega_m
h^2=0.135+0.008-0.009, tau=0.17+-0.06, n_s(0.05/Mpc)=0.93+-0.03, and
sigma_8=0.84+-0.04. WMAP's best determination of tau=0.17+-0.04 arises directly
from the TE data and not from this model fit, but they are consistent. These
parameters imply that the age of the universe is 13.7+-0.2 Gyr. The data favors
but does not require a slowly varying spectral index. By combining WMAP data
with other astronomical data sets, we constrain the geometry of the universe,
Omega_tot = 1.02 +- 0.02, the equation of state of the dark energy w < -0.78
(95% confidence limit assuming w >= -1), and the energy density in stable
neutrinos, Omega_nu h^2 < 0.0076 (95% confidence limit). For 3 degenerate
neutrino species, this limit implies that their mass is less than 0.23 eV (95%
confidence limit). The WMAP detection of early reionization rules out warm dark
matter.
","D. N. Spergel (1), L. Verde (1), H. V. Peiris (1), E. Komatsu (1), M.
  R. Nolta (1), C. L. Bennett (2), M. Halpern (4), G. Hinshaw (2), N. Jarosik
  (1), A. Kogut (2), M. Limon (2), S. S. Meyer (5), L. Page (1), G. S. Tucker
  (2), J. L. Weiland (7), E. Wollack (2), E. L. Wright (8) ((1) Princeton, (3)
  NASA's GSFC, (4) UBC, (5) U. Chicaco, (6) Brown, (7) SSAI, (8) UCLA)","Astrophys.J.Suppl.148:175-194,2003",Physics,Physics
2004,astro-ph/0302209,332,"First Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Determination of Cosmological Parameters","  WMAP precision data enables accurate testing of cosmological models. We find
that the emerging standard model of cosmology, a flat Lambda-dominated universe
seeded by nearly scale-invariant adiabatic Gaussian fluctuations, fits the WMAP
data. With parameters fixed only by WMAP data, we can fit finer scale CMB
measurements and measurements of large scle structure (galaxy surveys and the
Lyman alpha forest). This simple model is also consistent with a host of other
astronomical measurements. We then fit the model parameters to a combination of
WMAP data with other finer scale CMB experiments (ACBAR and CBI), 2dFGRS
measurements and Lyman alpha forest data to find the model's best fit
cosmological parameters: h=0.71+0.04-0.03, Omega_b h^2=0.0224+-0.0009, Omega_m
h^2=0.135+0.008-0.009, tau=0.17+-0.06, n_s(0.05/Mpc)=0.93+-0.03, and
sigma_8=0.84+-0.04. WMAP's best determination of tau=0.17+-0.04 arises directly
from the TE data and not from this model fit, but they are consistent. These
parameters imply that the age of the universe is 13.7+-0.2 Gyr. The data favors
but does not require a slowly varying spectral index. By combining WMAP data
with other astronomical data sets, we constrain the geometry of the universe,
Omega_tot = 1.02 +- 0.02, the equation of state of the dark energy w < -0.78
(95% confidence limit assuming w >= -1), and the energy density in stable
neutrinos, Omega_nu h^2 < 0.0076 (95% confidence limit). For 3 degenerate
neutrino species, this limit implies that their mass is less than 0.23 eV (95%
confidence limit). The WMAP detection of early reionization rules out warm dark
matter.
","D. N. Spergel (1), L. Verde (1), H. V. Peiris (1), E. Komatsu (1), M.
  R. Nolta (1), C. L. Bennett (2), M. Halpern (4), G. Hinshaw (2), N. Jarosik
  (1), A. Kogut (2), M. Limon (2), S. S. Meyer (5), L. Page (1), G. S. Tucker
  (2), J. L. Weiland (7), E. Wollack (2), E. L. Wright (8) ((1) Princeton, (3)
  NASA's GSFC, (4) UBC, (5) U. Chicaco, (6) Brown, (7) SSAI, (8) UCLA)","Astrophys.J.Suppl.148:175-194,2003",Physics,Physics
2005,astro-ph/0302209,260,"First Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Determination of Cosmological Parameters","  WMAP precision data enables accurate testing of cosmological models. We find
that the emerging standard model of cosmology, a flat Lambda-dominated universe
seeded by nearly scale-invariant adiabatic Gaussian fluctuations, fits the WMAP
data. With parameters fixed only by WMAP data, we can fit finer scale CMB
measurements and measurements of large scle structure (galaxy surveys and the
Lyman alpha forest). This simple model is also consistent with a host of other
astronomical measurements. We then fit the model parameters to a combination of
WMAP data with other finer scale CMB experiments (ACBAR and CBI), 2dFGRS
measurements and Lyman alpha forest data to find the model's best fit
cosmological parameters: h=0.71+0.04-0.03, Omega_b h^2=0.0224+-0.0009, Omega_m
h^2=0.135+0.008-0.009, tau=0.17+-0.06, n_s(0.05/Mpc)=0.93+-0.03, and
sigma_8=0.84+-0.04. WMAP's best determination of tau=0.17+-0.04 arises directly
from the TE data and not from this model fit, but they are consistent. These
parameters imply that the age of the universe is 13.7+-0.2 Gyr. The data favors
but does not require a slowly varying spectral index. By combining WMAP data
with other astronomical data sets, we constrain the geometry of the universe,
Omega_tot = 1.02 +- 0.02, the equation of state of the dark energy w < -0.78
(95% confidence limit assuming w >= -1), and the energy density in stable
neutrinos, Omega_nu h^2 < 0.0076 (95% confidence limit). For 3 degenerate
neutrino species, this limit implies that their mass is less than 0.23 eV (95%
confidence limit). The WMAP detection of early reionization rules out warm dark
matter.
","D. N. Spergel (1), L. Verde (1), H. V. Peiris (1), E. Komatsu (1), M.
  R. Nolta (1), C. L. Bennett (2), M. Halpern (4), G. Hinshaw (2), N. Jarosik
  (1), A. Kogut (2), M. Limon (2), S. S. Meyer (5), L. Page (1), G. S. Tucker
  (2), J. L. Weiland (7), E. Wollack (2), E. L. Wright (8) ((1) Princeton, (3)
  NASA's GSFC, (4) UBC, (5) U. Chicaco, (6) Brown, (7) SSAI, (8) UCLA)","Astrophys.J.Suppl.148:175-194,2003",Physics,Physics
2004,hep-ph/9905221,220,A Large Mass Hierarchy from a Small Extra Dimension,"  We propose a new higher-dimensional mechanism for solving the Hierarchy
Problem. The Weak scale is generated from a large scale of order the Planck
scale through an exponential hierarchy. However, this exponential arises not
from gauge interactions but from the background metric (which is a slice of
AdS_5 spacetime). This mechanism relies on the existence of only a single
additional dimension. We demonstrate a simple explicit example of this
mechanism with two three-branes, one of which contains the Standard Model
fields. The experimental consequences of this scenario are new and dramatic.
There are fundamental spin-2 excitations with mass of weak scale order, which
are coupled with weak scale as opposed to gravitational strength to the
standard model particles. The phenomenology of these models is quite distinct
from that of large extra dimension scenarios; none of the current constraints
on theories with very large extra dimensions apply.
","Lisa Randall, Raman Sundrum","Phys.Rev.Lett.83:3370-3373,1999",Physics,Physics
2006,astro-ph/0603449,525,"Wilkinson Microwave Anisotropy Probe (WMAP) Three Year Results:
  Implications for Cosmology","  A simple cosmological model with only six parameters (matter density, Omega_m
h^2, baryon density, Omega_b h^2, Hubble Constant, H_0, amplitude of
fluctuations, sigma_8, optical depth, tau, and a slope for the scalar
perturbation spectrum, n_s) fits not only the three year WMAP temperature and
polarization data, but also small scale CMB data, light element abundances,
large-scale structure observations, and the supernova luminosity/distance
relationship. Using WMAP data only, the best fit values for cosmological
parameters for the power-law flat LCDM model are (Omega_m h^2, Omega_b h^2, h,
n_s, tau, sigma_8) = 0.1277+0.0080-0.0079, 0.02229+-0.00073, 0.732+0.031-0.032,
0.958+-0.016, 0.089+-0.030, 0.761+0.049-0.048). The three year data
dramatically shrink the allowed volume in this six dimensional parameter space.
Assuming that the primordial fluctuations are adiabatic with a power law
spectrum, the WMAP data_alone_ require dark matter, and favor a spectral index
that is significantly less than the Harrison-Zel'dovich-Peebles scale-invariant
spectrum (n_s=1, r=0). Models that suppress large-scale power through a running
spectral index or a large-scale cut-off in the power spectrum are a better fit
to the WMAP and small scale CMB data than the power-law LCDM model; however,
the improvement in the fit to the WMAP data is only Delta chi^2 = 3 for 1 extra
degree of freedom. The combination of WMAP and other astronomical data yields
significant constraints on the geometry of the universe, the equation of state
of the dark energy, the gravitational wave energy density, and neutrino
properties. Consistent with the predictions of simple inflationary theories, we
detect no significant deviations from Gaussianity in the CMB maps.
","D. N. Spergel, R. Bean, O. Dor\'e, M. R. Nolta, C. L. Bennett, J.
  Dunkley, G. Hinshaw, N. Jarosik, E. Komatsu, L. Page, H. V. Peiris, L. Verde,
  M. Halpern, R. S. Hill, A. Kogut, M. Limon, S. S. Meyer, N. Odegard, G. S.
  Tucker, J. L. Weiland, E. Wollack, E. L. Wright","Astrophys.J.Suppl.170:377,2007",Physics,Physics
2007,astro-ph/0603449,580,"Wilkinson Microwave Anisotropy Probe (WMAP) Three Year Results:
  Implications for Cosmology","  A simple cosmological model with only six parameters (matter density, Omega_m
h^2, baryon density, Omega_b h^2, Hubble Constant, H_0, amplitude of
fluctuations, sigma_8, optical depth, tau, and a slope for the scalar
perturbation spectrum, n_s) fits not only the three year WMAP temperature and
polarization data, but also small scale CMB data, light element abundances,
large-scale structure observations, and the supernova luminosity/distance
relationship. Using WMAP data only, the best fit values for cosmological
parameters for the power-law flat LCDM model are (Omega_m h^2, Omega_b h^2, h,
n_s, tau, sigma_8) = 0.1277+0.0080-0.0079, 0.02229+-0.00073, 0.732+0.031-0.032,
0.958+-0.016, 0.089+-0.030, 0.761+0.049-0.048). The three year data
dramatically shrink the allowed volume in this six dimensional parameter space.
Assuming that the primordial fluctuations are adiabatic with a power law
spectrum, the WMAP data_alone_ require dark matter, and favor a spectral index
that is significantly less than the Harrison-Zel'dovich-Peebles scale-invariant
spectrum (n_s=1, r=0). Models that suppress large-scale power through a running
spectral index or a large-scale cut-off in the power spectrum are a better fit
to the WMAP and small scale CMB data than the power-law LCDM model; however,
the improvement in the fit to the WMAP data is only Delta chi^2 = 3 for 1 extra
degree of freedom. The combination of WMAP and other astronomical data yields
significant constraints on the geometry of the universe, the equation of state
of the dark energy, the gravitational wave energy density, and neutrino
properties. Consistent with the predictions of simple inflationary theories, we
detect no significant deviations from Gaussianity in the CMB maps.
","D. N. Spergel, R. Bean, O. Dor\'e, M. R. Nolta, C. L. Bennett, J.
  Dunkley, G. Hinshaw, N. Jarosik, E. Komatsu, L. Page, H. V. Peiris, L. Verde,
  M. Halpern, R. S. Hill, A. Kogut, M. Limon, S. S. Meyer, N. Odegard, G. S.
  Tucker, J. L. Weiland, E. Wollack, E. L. Wright","Astrophys.J.Suppl.170:377,2007",Physics,Physics
2008,0803.0547,410,"Five-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Cosmological Interpretation","  (Abridged) The WMAP 5-year data strongly limit deviations from the minimal
LCDM model. We constrain the physics of inflation via Gaussianity,
adiabaticity, the power spectrum shape, gravitational waves, and spatial
curvature. We also constrain the properties of dark energy, parity-violation,
and neutrinos. We detect no convincing deviations from the minimal model. The
parameters of the LCDM model, derived from WMAP combined with the distance
measurements from the Type Ia supernovae (SN) and the Baryon Acoustic
Oscillations (BAO), are: Omega_b=0.0456+-0.0015, Omega_c=0.228+-0.013,
Omega_Lambda=0.726+-0.015, H_0=70.5+-1.3 km/s/Mpc, n_s=0.960+-0.013,
tau=0.084+-0.016, and sigma_8=0.812+-0.026. With WMAP+BAO+SN, we find the
tensor-to-scalar ratio r<0.22 (95% CL), and n_s>1 is disfavored regardless of
r. We obtain tight, simultaneous limits on the (constant) equation of state of
dark energy and curvature. We provide a set of ""WMAP distance priors,"" to test
a variety of dark energy models. We test a time-dependent w with a present
value constrained as -0.33<1+w_0<0.21 (95% CL). Temperature and matter
fluctuations obey the adiabatic relation to within 8.9% and 2.1% for the axion
and curvaton-type dark matter, respectively. The TE and EB spectra constrain
cosmic parity-violation. We find the limit on the total mass of neutrinos,
sum(m_nu)<0.67 eV (95% CL), which is free from the uncertainty in the
normalization of the large-scale structure data. The effective number of
neutrino species is constrained as N_{eff} = 4.4+-1.5 (68%), consistent with
the standard value of 3.04. Finally, limits on primordial non-Gaussianity are
-9<f_{NL}^{local}<111 and -151<f_{NL}^{equil}<253 (95% CL) for the local and
equilateral models, respectively.
","E. Komatsu, J. Dunkley, M. R. Nolta, C. L. Bennett, B. Gold, G.
  Hinshaw, N. Jarosik, D. Larson, M. Limon, L. Page, D. N. Spergel, M. Halpern,
  R. S. Hill, A. Kogut, S. S. Meyer, G. S. Tucker, J. L. Weiland, E. Wollack,
  E. L. Wright","Astrophys.J.Suppl.180:330-376,2009",Physics,Physics
2009,0803.0547,645,"Five-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Cosmological Interpretation","  (Abridged) The WMAP 5-year data strongly limit deviations from the minimal
LCDM model. We constrain the physics of inflation via Gaussianity,
adiabaticity, the power spectrum shape, gravitational waves, and spatial
curvature. We also constrain the properties of dark energy, parity-violation,
and neutrinos. We detect no convincing deviations from the minimal model. The
parameters of the LCDM model, derived from WMAP combined with the distance
measurements from the Type Ia supernovae (SN) and the Baryon Acoustic
Oscillations (BAO), are: Omega_b=0.0456+-0.0015, Omega_c=0.228+-0.013,
Omega_Lambda=0.726+-0.015, H_0=70.5+-1.3 km/s/Mpc, n_s=0.960+-0.013,
tau=0.084+-0.016, and sigma_8=0.812+-0.026. With WMAP+BAO+SN, we find the
tensor-to-scalar ratio r<0.22 (95% CL), and n_s>1 is disfavored regardless of
r. We obtain tight, simultaneous limits on the (constant) equation of state of
dark energy and curvature. We provide a set of ""WMAP distance priors,"" to test
a variety of dark energy models. We test a time-dependent w with a present
value constrained as -0.33<1+w_0<0.21 (95% CL). Temperature and matter
fluctuations obey the adiabatic relation to within 8.9% and 2.1% for the axion
and curvaton-type dark matter, respectively. The TE and EB spectra constrain
cosmic parity-violation. We find the limit on the total mass of neutrinos,
sum(m_nu)<0.67 eV (95% CL), which is free from the uncertainty in the
normalization of the large-scale structure data. The effective number of
neutrino species is constrained as N_{eff} = 4.4+-1.5 (68%), consistent with
the standard value of 3.04. Finally, limits on primordial non-Gaussianity are
-9<f_{NL}^{local}<111 and -151<f_{NL}^{equil}<253 (95% CL) for the local and
equilateral models, respectively.
","E. Komatsu, J. Dunkley, M. R. Nolta, C. L. Bennett, B. Gold, G.
  Hinshaw, N. Jarosik, D. Larson, M. Limon, L. Page, D. N. Spergel, M. Halpern,
  R. S. Hill, A. Kogut, S. S. Meyer, G. S. Tucker, J. L. Weiland, E. Wollack,
  E. L. Wright","Astrophys.J.Suppl.180:330-376,2009",Physics,Physics
2010,1001.4538,743,"Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Cosmological Interpretation","  (Abridged) The 7-year WMAP data and improved astrophysical data rigorously
test the standard cosmological model and its extensions. By combining WMAP with
the latest distance measurements from BAO and H0 measurement, we determine the
parameters of the simplest LCDM model. The power-law index of the primordial
power spectrum is n_s=0.968+-0.012, a measurement that excludes the
scale-invariant spectrum by 99.5%CL. The other parameters are also improved
from the 5-year results. Notable examples of improved parameters are the total
mass of neutrinos, sum(m_nu)<0.58eV, and the effective number of neutrino
species, N_eff=4.34+0.86-0.88. We detect the effect of primordial helium on the
temperature power spectrum and provide a new test of big bang nucleosynthesis.
We detect, and show on the map for the first time, the tangential and radial
polarization patterns around hot and cold spots of temperature fluctuations, an
important test of physical processes at z=1090 and the dominance of adiabatic
scalar fluctuations. With the 7-year TB power spectrum, the limit on a rotation
of the polarization plane due to potential parity-violating effects has
improved to Delta(alpha)=-1.1+-1.4(stat)+-1.5(syst) degrees. We report
significant detections of the SZ effect at the locations of known clusters of
galaxies. The measured SZ signal agrees well with the expected signal from the
X-ray data. However, it is a factor of 0.5 to 0.7 times the predictions from
""universal profile"" of Arnaud et al., analytical models, and hydrodynamical
simulations. We find, for the first time in the SZ effect, a significant
difference between the cooling-flow and non-cooling-flow clusters (or relaxed
and non-relaxed clusters), which can explain some of the discrepancy. This
lower amplitude is consistent with the lower-than-theoretically-expected SZ
power spectrum recently measured by the South Pole Telescope collaboration.
","E. Komatsu, K. M. Smith, J. Dunkley, C. L. Bennett, B. Gold, G.
  Hinshaw, N. Jarosik, D. Larson, M. R. Nolta, L. Page, D. N. Spergel, M.
  Halpern, R. S. Hill, A. Kogut, M. Limon, S. S. Meyer, N. Odegard, G. S.
  Tucker, J. L. Weiland, E. Wollack, E. L. Wright","Astrophys.J.Suppl.192:18,2011",Physics,Physics
2011,1001.4538,649,"Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Cosmological Interpretation","  (Abridged) The 7-year WMAP data and improved astrophysical data rigorously
test the standard cosmological model and its extensions. By combining WMAP with
the latest distance measurements from BAO and H0 measurement, we determine the
parameters of the simplest LCDM model. The power-law index of the primordial
power spectrum is n_s=0.968+-0.012, a measurement that excludes the
scale-invariant spectrum by 99.5%CL. The other parameters are also improved
from the 5-year results. Notable examples of improved parameters are the total
mass of neutrinos, sum(m_nu)<0.58eV, and the effective number of neutrino
species, N_eff=4.34+0.86-0.88. We detect the effect of primordial helium on the
temperature power spectrum and provide a new test of big bang nucleosynthesis.
We detect, and show on the map for the first time, the tangential and radial
polarization patterns around hot and cold spots of temperature fluctuations, an
important test of physical processes at z=1090 and the dominance of adiabatic
scalar fluctuations. With the 7-year TB power spectrum, the limit on a rotation
of the polarization plane due to potential parity-violating effects has
improved to Delta(alpha)=-1.1+-1.4(stat)+-1.5(syst) degrees. We report
significant detections of the SZ effect at the locations of known clusters of
galaxies. The measured SZ signal agrees well with the expected signal from the
X-ray data. However, it is a factor of 0.5 to 0.7 times the predictions from
""universal profile"" of Arnaud et al., analytical models, and hydrodynamical
simulations. We find, for the first time in the SZ effect, a significant
difference between the cooling-flow and non-cooling-flow clusters (or relaxed
and non-relaxed clusters), which can explain some of the discrepancy. This
lower amplitude is consistent with the lower-than-theoretically-expected SZ
power spectrum recently measured by the South Pole Telescope collaboration.
","E. Komatsu, K. M. Smith, J. Dunkley, C. L. Bennett, B. Gold, G.
  Hinshaw, N. Jarosik, D. Larson, M. R. Nolta, L. Page, D. N. Spergel, M.
  Halpern, R. S. Hill, A. Kogut, M. Limon, S. S. Meyer, N. Odegard, G. S.
  Tucker, J. L. Weiland, E. Wollack, E. L. Wright","Astrophys.J.Suppl.192:18,2011",Physics,Physics
2012,1001.4538,695,"Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Cosmological Interpretation","  (Abridged) The 7-year WMAP data and improved astrophysical data rigorously
test the standard cosmological model and its extensions. By combining WMAP with
the latest distance measurements from BAO and H0 measurement, we determine the
parameters of the simplest LCDM model. The power-law index of the primordial
power spectrum is n_s=0.968+-0.012, a measurement that excludes the
scale-invariant spectrum by 99.5%CL. The other parameters are also improved
from the 5-year results. Notable examples of improved parameters are the total
mass of neutrinos, sum(m_nu)<0.58eV, and the effective number of neutrino
species, N_eff=4.34+0.86-0.88. We detect the effect of primordial helium on the
temperature power spectrum and provide a new test of big bang nucleosynthesis.
We detect, and show on the map for the first time, the tangential and radial
polarization patterns around hot and cold spots of temperature fluctuations, an
important test of physical processes at z=1090 and the dominance of adiabatic
scalar fluctuations. With the 7-year TB power spectrum, the limit on a rotation
of the polarization plane due to potential parity-violating effects has
improved to Delta(alpha)=-1.1+-1.4(stat)+-1.5(syst) degrees. We report
significant detections of the SZ effect at the locations of known clusters of
galaxies. The measured SZ signal agrees well with the expected signal from the
X-ray data. However, it is a factor of 0.5 to 0.7 times the predictions from
""universal profile"" of Arnaud et al., analytical models, and hydrodynamical
simulations. We find, for the first time in the SZ effect, a significant
difference between the cooling-flow and non-cooling-flow clusters (or relaxed
and non-relaxed clusters), which can explain some of the discrepancy. This
lower amplitude is consistent with the lower-than-theoretically-expected SZ
power spectrum recently measured by the South Pole Telescope collaboration.
","E. Komatsu, K. M. Smith, J. Dunkley, C. L. Bennett, B. Gold, G.
  Hinshaw, N. Jarosik, D. Larson, M. R. Nolta, L. Page, D. N. Spergel, M.
  Halpern, R. S. Hill, A. Kogut, M. Limon, S. S. Meyer, N. Odegard, G. S.
  Tucker, J. L. Weiland, E. Wollack, E. L. Wright","Astrophys.J.Suppl.192:18,2011",Physics,Physics
2012,1207.7214,475,"Observation of a new particle in the search for the Standard Model Higgs
  boson with the ATLAS detector at the LHC","  A search for the Standard Model Higgs boson in proton-proton collisions with
the ATLAS detector at the LHC is presented. The datasets used correspond to
integrated luminosities of approximately 4.8 fb^-1 collected at sqrt(s) = 7 TeV
in 2011 and 5.8 fb^-1 at sqrt(s) = 8 TeV in 2012. Individual searches in the
channels H->ZZ^(*)->llll, H->gamma gamma and H->WW->e nu mu nu in the 8 TeV
data are combined with previously published results of searches for H->ZZ^(*),
WW^(*), bbbar and tau^+tau^- in the 7 TeV data and results from improved
analyses of the H->ZZ^(*)->llll and H->gamma gamma channels in the 7 TeV data.
Clear evidence for the production of a neutral boson with a measured mass of
126.0 +/- 0.4(stat) +/- 0.4(sys) GeV is presented. This observation, which has
a significance of 5.9 standard deviations, corresponding to a background
fluctuation probability of 1.7x10^-9, is compatible with the production and
decay of the Standard Model Higgs boson.
",The ATLAS Collaboration,Phys.Lett. B716 (2012) 1-29,Physics,Physics
2013,1207.7214,872,"Observation of a new particle in the search for the Standard Model Higgs
  boson with the ATLAS detector at the LHC","  A search for the Standard Model Higgs boson in proton-proton collisions with
the ATLAS detector at the LHC is presented. The datasets used correspond to
integrated luminosities of approximately 4.8 fb^-1 collected at sqrt(s) = 7 TeV
in 2011 and 5.8 fb^-1 at sqrt(s) = 8 TeV in 2012. Individual searches in the
channels H->ZZ^(*)->llll, H->gamma gamma and H->WW->e nu mu nu in the 8 TeV
data are combined with previously published results of searches for H->ZZ^(*),
WW^(*), bbbar and tau^+tau^- in the 7 TeV data and results from improved
analyses of the H->ZZ^(*)->llll and H->gamma gamma channels in the 7 TeV data.
Clear evidence for the production of a neutral boson with a measured mass of
126.0 +/- 0.4(stat) +/- 0.4(sys) GeV is presented. This observation, which has
a significance of 5.9 standard deviations, corresponding to a background
fluctuation probability of 1.7x10^-9, is compatible with the production and
decay of the Standard Model Higgs boson.
",The ATLAS Collaboration,Phys.Lett. B716 (2012) 1-29,Physics,Physics
2014,1207.7214,754,"Observation of a new particle in the search for the Standard Model Higgs
  boson with the ATLAS detector at the LHC","  A search for the Standard Model Higgs boson in proton-proton collisions with
the ATLAS detector at the LHC is presented. The datasets used correspond to
integrated luminosities of approximately 4.8 fb^-1 collected at sqrt(s) = 7 TeV
in 2011 and 5.8 fb^-1 at sqrt(s) = 8 TeV in 2012. Individual searches in the
channels H->ZZ^(*)->llll, H->gamma gamma and H->WW->e nu mu nu in the 8 TeV
data are combined with previously published results of searches for H->ZZ^(*),
WW^(*), bbbar and tau^+tau^- in the 7 TeV data and results from improved
analyses of the H->ZZ^(*)->llll and H->gamma gamma channels in the 7 TeV data.
Clear evidence for the production of a neutral boson with a measured mass of
126.0 +/- 0.4(stat) +/- 0.4(sys) GeV is presented. This observation, which has
a significance of 5.9 standard deviations, corresponding to a background
fluctuation probability of 1.7x10^-9, is compatible with the production and
decay of the Standard Model Higgs boson.
",The ATLAS Collaboration,Phys.Lett. B716 (2012) 1-29,Physics,Physics
2015,1207.7214,732,"Observation of a new particle in the search for the Standard Model Higgs
  boson with the ATLAS detector at the LHC","  A search for the Standard Model Higgs boson in proton-proton collisions with
the ATLAS detector at the LHC is presented. The datasets used correspond to
integrated luminosities of approximately 4.8 fb^-1 collected at sqrt(s) = 7 TeV
in 2011 and 5.8 fb^-1 at sqrt(s) = 8 TeV in 2012. Individual searches in the
channels H->ZZ^(*)->llll, H->gamma gamma and H->WW->e nu mu nu in the 8 TeV
data are combined with previously published results of searches for H->ZZ^(*),
WW^(*), bbbar and tau^+tau^- in the 7 TeV data and results from improved
analyses of the H->ZZ^(*)->llll and H->gamma gamma channels in the 7 TeV data.
Clear evidence for the production of a neutral boson with a measured mass of
126.0 +/- 0.4(stat) +/- 0.4(sys) GeV is presented. This observation, which has
a significance of 5.9 standard deviations, corresponding to a background
fluctuation probability of 1.7x10^-9, is compatible with the production and
decay of the Standard Model Higgs boson.
",The ATLAS Collaboration,Phys.Lett. B716 (2012) 1-29,Physics,Physics
2013,1303.5076,1119,Planck 2013 results. XVI. Cosmological parameters,"  We present the first results based on Planck measurements of the CMB
temperature and lensing-potential power spectra. The Planck spectra at high
multipoles are extremely well described by the standard spatially-flat
six-parameter LCDM cosmology. In this model Planck data determine the
cosmological parameters to high precision. We find a low value of the Hubble
constant, H0=67.3+/-1.2 km/s/Mpc and a high value of the matter density
parameter, Omega_m=0.315+/-0.017 (+/-1 sigma errors) in excellent agreement
with constraints from baryon acoustic oscillation (BAO) surveys. Including
curvature, we find that the Universe is consistent with spatial flatness to
percent-level precision using Planck CMB data alone. We present results from an
analysis of extensions to the standard cosmology, using astrophysical data sets
in addition to Planck and high-resolution CMB data. None of these models are
favoured significantly over standard LCDM. The deviation of the scalar spectral
index from unity is insensitive to the addition of tensor modes and to changes
in the matter content of the Universe. We find a 95% upper limit of r<0.11 on
the tensor-to-scalar ratio. There is no evidence for additional neutrino-like
relativistic particles. Using BAO and CMB data, we find N_eff=3.30+/-0.27 for
the effective number of relativistic degrees of freedom, and an upper limit of
0.23 eV for the summed neutrino mass. Our results are in excellent agreement
with big bang nucleosynthesis and the standard value of N_eff=3.046. We find no
evidence for dynamical dark energy. Despite the success of the standard LCDM
model, this cosmology does not provide a good fit to the CMB power spectrum at
low multipoles, as noted previously by the WMAP team. While not of decisive
significance, this is an anomaly in an otherwise self-consistent analysis of
the Planck temperature data.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, C. Armitage-Caplan, M.
  Arnaud, M. Ashdown, F. Atrio-Barandela, J. Aumont, C. Baccigalupi, A. J.
  Banday, R. B. Barreiro, J. G. Bartlett, E. Battaner, K. Benabed, A. Beno\^it,
  A. Benoit-L\'evy, J.-P. Bernard, M. Bersanelli, P. Bielewicz, J. Bobin, J. J.
  Bock, A. Bonaldi, J. R. Bond, J. Borrill, F. R. Bouchet, M. Bridges, M.
  Bucher, C. Burigana, R. C. Butler, E. Calabrese, B. Cappellini, J.-F.
  Cardoso, A. Catalano, A. Challinor, A. Chamballu, R.-R. Chary, X. Chen, H. C.
  Chiang, L.-Y Chiang, P. R. Christensen, S. Church, D. L. Clements, S.
  Colombi, L. P. L. Colombo, F. Couchot, A. Coulais, B. P. Crill, A. Curto, F.
  Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P. de Bernardis, A. de Rosa,
  G. de Zotti, J. Delabrouille, J.-M. Delouis, F.-X. D\'esert, C. Dickinson, J.
  M. Diego, K. Dolag, H. Dole, S. Donzelli, O. Dor\'e, M. Douspis, J. Dunkley,
  X. Dupac, G. Efstathiou, F. Elsner, T. A. En{\ss}lin, H. K. Eriksen, F.
  Finelli, O. Forni, M. Frailis, A. A. Fraisse, E. Franceschi, T. C. Gaier, S.
  Galeotta, S. Galli, K. Ganga, M. Giard, G. Giardino, Y. Giraud-H\'eraud, E.
  Gjerl{\o}w, J. Gonz\'alez-Nuevo, K. M. G\'orski, S. Gratton, A. Gregorio, A.
  Gruppuso, J. E. Gudmundsson, J. Haissinski, J. Hamann, F. K. Hansen, D.
  Hanson, D. Harrison, S. Henrot-Versill\'e, C. Hern\'andez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  Z. Hou, W. Hovest, K. M. Huffenberger, A. H. Jaffe, T. R. Jaffe, J. Jewell,
  W. C. Jones, M. Juvela, E. Keih\""anen, R. Keskitalo, T. S. Kisner, R.
  Kneissl, J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A.
  L\""ahteenm\""aki, J.-M. Lamarre, A. Lasenby, M. Lattanzi, R. J. Laureijs, C.
  R. Lawrence, S. Leach, J. P. Leahy, R. Leonardi, J. Le\'on-Tavares, J.
  Lesgourgues, A. Lewis, M. Liguori, P. B. Lilje, M. Linden-V{\o}rnle, M.
  L\'opez-Caniego, P. M. Lubin, J. F. Mac\'ias-P\'erez, B. Maffei, D. Maino, N.
  Mandolesi, M. Maris, D. J. Marshall, P. G. Martin, E. Mart\'inez-Gonz\'alez,
  S. Masi, M. Massardi, S. Matarrese, F. Matthai, P. Mazzotta, P. R. Meinhold,
  A. Melchiorri, J.-B. Melin, L. Mendes, E. Menegoni, A. Mennella, M.
  Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Desch\^enes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. N{\o}rgaard-Nielsen,
  F. Noviello, D. Novikov, I. Novikov, I. J. O'Dwyer, S. Osborne, C. A.
  Oxborrow, F. Paci, L. Pagano, F. Pajot, D. Paoletti, B. Partridge, F. Pasian,
  G. Patanchon, D. Pearson, T. J. Pearson, H. V. Peiris, O. Perdereau, L.
  Perotto, F. Perrotta, V. Pettorino, F. Piacentini, M. Piat, E. Pierpaoli, D.
  Pietrobon, S. Plaszczynski, P. Platania, E. Pointecouteau, G. Polenta, N.
  Ponthieu, L. Popa, T. Poutanen, G. W. Pratt, G. Pr\'ezeau, S. Prunet, J.-L.
  Puget, J. P. Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C.
  Renault, S. Ricciardi, T. Riller, I. Ristorcelli, G. Rocha, C. Rosset, G.
  Roudier, M. Rowan-Robinson, J. A. Rubi\~no-Mart\'in, B. Rusholme, M. Sandri,
  D. Santos, M. Savelainen, G. Savini, D. Scott, M. D. Seiffert, E. P. S.
  Shellard, L. D. Spencer, J.-L. Starck, V. Stolyarov, R. Stompor, R. Sudiwala,
  R. Sunyaev, F. Sureau, D. Sutton, A.-S. Suur-Uski, J.-F. Sygnet, J. A.
  Tauber, D. Tavagnacco, L. Terenzi, L. Toffolatti, M. Tomasi, M. Tristram, M.
  Tucci, J. Tuovinen, M. T\""urler, G. Umana, L. Valenziano, J. Valiviita, B.
  Van Tent, P. Vielva, F. Villa, N. Vittorio, L. A. Wade, B. D. Wandelt, I. K.
  Wehus, M. White, S. D. M. White, A. Wilkinson, D. Yvon, A. Zacchei, A. Zonca",,Physics,Physics
2014,1303.5076,1536,Planck 2013 results. XVI. Cosmological parameters,"  We present the first results based on Planck measurements of the CMB
temperature and lensing-potential power spectra. The Planck spectra at high
multipoles are extremely well described by the standard spatially-flat
six-parameter LCDM cosmology. In this model Planck data determine the
cosmological parameters to high precision. We find a low value of the Hubble
constant, H0=67.3+/-1.2 km/s/Mpc and a high value of the matter density
parameter, Omega_m=0.315+/-0.017 (+/-1 sigma errors) in excellent agreement
with constraints from baryon acoustic oscillation (BAO) surveys. Including
curvature, we find that the Universe is consistent with spatial flatness to
percent-level precision using Planck CMB data alone. We present results from an
analysis of extensions to the standard cosmology, using astrophysical data sets
in addition to Planck and high-resolution CMB data. None of these models are
favoured significantly over standard LCDM. The deviation of the scalar spectral
index from unity is insensitive to the addition of tensor modes and to changes
in the matter content of the Universe. We find a 95% upper limit of r<0.11 on
the tensor-to-scalar ratio. There is no evidence for additional neutrino-like
relativistic particles. Using BAO and CMB data, we find N_eff=3.30+/-0.27 for
the effective number of relativistic degrees of freedom, and an upper limit of
0.23 eV for the summed neutrino mass. Our results are in excellent agreement
with big bang nucleosynthesis and the standard value of N_eff=3.046. We find no
evidence for dynamical dark energy. Despite the success of the standard LCDM
model, this cosmology does not provide a good fit to the CMB power spectrum at
low multipoles, as noted previously by the WMAP team. While not of decisive
significance, this is an anomaly in an otherwise self-consistent analysis of
the Planck temperature data.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, C. Armitage-Caplan, M.
  Arnaud, M. Ashdown, F. Atrio-Barandela, J. Aumont, C. Baccigalupi, A. J.
  Banday, R. B. Barreiro, J. G. Bartlett, E. Battaner, K. Benabed, A. Beno\^it,
  A. Benoit-L\'evy, J.-P. Bernard, M. Bersanelli, P. Bielewicz, J. Bobin, J. J.
  Bock, A. Bonaldi, J. R. Bond, J. Borrill, F. R. Bouchet, M. Bridges, M.
  Bucher, C. Burigana, R. C. Butler, E. Calabrese, B. Cappellini, J.-F.
  Cardoso, A. Catalano, A. Challinor, A. Chamballu, R.-R. Chary, X. Chen, H. C.
  Chiang, L.-Y Chiang, P. R. Christensen, S. Church, D. L. Clements, S.
  Colombi, L. P. L. Colombo, F. Couchot, A. Coulais, B. P. Crill, A. Curto, F.
  Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P. de Bernardis, A. de Rosa,
  G. de Zotti, J. Delabrouille, J.-M. Delouis, F.-X. D\'esert, C. Dickinson, J.
  M. Diego, K. Dolag, H. Dole, S. Donzelli, O. Dor\'e, M. Douspis, J. Dunkley,
  X. Dupac, G. Efstathiou, F. Elsner, T. A. En{\ss}lin, H. K. Eriksen, F.
  Finelli, O. Forni, M. Frailis, A. A. Fraisse, E. Franceschi, T. C. Gaier, S.
  Galeotta, S. Galli, K. Ganga, M. Giard, G. Giardino, Y. Giraud-H\'eraud, E.
  Gjerl{\o}w, J. Gonz\'alez-Nuevo, K. M. G\'orski, S. Gratton, A. Gregorio, A.
  Gruppuso, J. E. Gudmundsson, J. Haissinski, J. Hamann, F. K. Hansen, D.
  Hanson, D. Harrison, S. Henrot-Versill\'e, C. Hern\'andez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  Z. Hou, W. Hovest, K. M. Huffenberger, A. H. Jaffe, T. R. Jaffe, J. Jewell,
  W. C. Jones, M. Juvela, E. Keih\""anen, R. Keskitalo, T. S. Kisner, R.
  Kneissl, J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A.
  L\""ahteenm\""aki, J.-M. Lamarre, A. Lasenby, M. Lattanzi, R. J. Laureijs, C.
  R. Lawrence, S. Leach, J. P. Leahy, R. Leonardi, J. Le\'on-Tavares, J.
  Lesgourgues, A. Lewis, M. Liguori, P. B. Lilje, M. Linden-V{\o}rnle, M.
  L\'opez-Caniego, P. M. Lubin, J. F. Mac\'ias-P\'erez, B. Maffei, D. Maino, N.
  Mandolesi, M. Maris, D. J. Marshall, P. G. Martin, E. Mart\'inez-Gonz\'alez,
  S. Masi, M. Massardi, S. Matarrese, F. Matthai, P. Mazzotta, P. R. Meinhold,
  A. Melchiorri, J.-B. Melin, L. Mendes, E. Menegoni, A. Mennella, M.
  Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Desch\^enes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. N{\o}rgaard-Nielsen,
  F. Noviello, D. Novikov, I. Novikov, I. J. O'Dwyer, S. Osborne, C. A.
  Oxborrow, F. Paci, L. Pagano, F. Pajot, D. Paoletti, B. Partridge, F. Pasian,
  G. Patanchon, D. Pearson, T. J. Pearson, H. V. Peiris, O. Perdereau, L.
  Perotto, F. Perrotta, V. Pettorino, F. Piacentini, M. Piat, E. Pierpaoli, D.
  Pietrobon, S. Plaszczynski, P. Platania, E. Pointecouteau, G. Polenta, N.
  Ponthieu, L. Popa, T. Poutanen, G. W. Pratt, G. Pr\'ezeau, S. Prunet, J.-L.
  Puget, J. P. Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C.
  Renault, S. Ricciardi, T. Riller, I. Ristorcelli, G. Rocha, C. Rosset, G.
  Roudier, M. Rowan-Robinson, J. A. Rubi\~no-Mart\'in, B. Rusholme, M. Sandri,
  D. Santos, M. Savelainen, G. Savini, D. Scott, M. D. Seiffert, E. P. S.
  Shellard, L. D. Spencer, J.-L. Starck, V. Stolyarov, R. Stompor, R. Sudiwala,
  R. Sunyaev, F. Sureau, D. Sutton, A.-S. Suur-Uski, J.-F. Sygnet, J. A.
  Tauber, D. Tavagnacco, L. Terenzi, L. Toffolatti, M. Tomasi, M. Tristram, M.
  Tucci, J. Tuovinen, M. T\""urler, G. Umana, L. Valenziano, J. Valiviita, B.
  Van Tent, P. Vielva, F. Villa, N. Vittorio, L. A. Wade, B. D. Wandelt, I. K.
  Wehus, M. White, S. D. M. White, A. Wilkinson, D. Yvon, A. Zacchei, A. Zonca",,Physics,Physics
2013,1207.7235,860,"Observation of a new boson at a mass of 125 GeV with the CMS experiment
  at the LHC","  Results are presented from searches for the standard model Higgs boson in
proton-proton collisions at sqrt(s) = 7 and 8 TeV in the Compact Muon Solenoid
experiment at the LHC, using data samples corresponding to integrated
luminosities of up to 5.1 inverse femtobarns at 7 TeV and 5.3 inverse
femtobarns at 8 TeV. The search is performed in five decay modes: gamma gamma,
ZZ, WW, tau tau, and b b-bar. An excess of events is observed above the
expected background, with a local significance of 5.0 standard deviations, at a
mass near 125 GeV, signalling the production of a new particle. The expected
significance for a standard model Higgs boson of that mass is 5.8 standard
deviations. The excess is most significant in the two decay modes with the best
mass resolution, gamma gamma and ZZ; a fit to these signals gives a mass of
125.3 +/- 0.4 (stat.) +/- 0.5 (syst.) GeV. The decay to two photons indicates
that the new particle is a boson with spin different from one.
",The CMS Collaboration,Phys. Lett. B 716 (2012) 30,Physics,Physics
2014,1207.7235,743,"Observation of a new boson at a mass of 125 GeV with the CMS experiment
  at the LHC","  Results are presented from searches for the standard model Higgs boson in
proton-proton collisions at sqrt(s) = 7 and 8 TeV in the Compact Muon Solenoid
experiment at the LHC, using data samples corresponding to integrated
luminosities of up to 5.1 inverse femtobarns at 7 TeV and 5.3 inverse
femtobarns at 8 TeV. The search is performed in five decay modes: gamma gamma,
ZZ, WW, tau tau, and b b-bar. An excess of events is observed above the
expected background, with a local significance of 5.0 standard deviations, at a
mass near 125 GeV, signalling the production of a new particle. The expected
significance for a standard model Higgs boson of that mass is 5.8 standard
deviations. The excess is most significant in the two decay modes with the best
mass resolution, gamma gamma and ZZ; a fit to these signals gives a mass of
125.3 +/- 0.4 (stat.) +/- 0.5 (syst.) GeV. The decay to two photons indicates
that the new particle is a boson with spin different from one.
",The CMS Collaboration,Phys. Lett. B 716 (2012) 30,Physics,Physics
2015,1207.7235,733,"Observation of a new boson at a mass of 125 GeV with the CMS experiment
  at the LHC","  Results are presented from searches for the standard model Higgs boson in
proton-proton collisions at sqrt(s) = 7 and 8 TeV in the Compact Muon Solenoid
experiment at the LHC, using data samples corresponding to integrated
luminosities of up to 5.1 inverse femtobarns at 7 TeV and 5.3 inverse
femtobarns at 8 TeV. The search is performed in five decay modes: gamma gamma,
ZZ, WW, tau tau, and b b-bar. An excess of events is observed above the
expected background, with a local significance of 5.0 standard deviations, at a
mass near 125 GeV, signalling the production of a new particle. The expected
significance for a standard model Higgs boson of that mass is 5.8 standard
deviations. The excess is most significant in the two decay modes with the best
mass resolution, gamma gamma and ZZ; a fit to these signals gives a mass of
125.3 +/- 0.4 (stat.) +/- 0.5 (syst.) GeV. The decay to two photons indicates
that the new particle is a boson with spin different from one.
",The CMS Collaboration,Phys. Lett. B 716 (2012) 30,Physics,Physics
2015,1502.01589,1069,Planck 2015 results. XIII. Cosmological parameters,"  We present results based on full-mission Planck observations of temperature
and polarization anisotropies of the CMB. These data are consistent with the
six-parameter inflationary LCDM cosmology. From the Planck temperature and
lensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9)
km/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar
spectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured
parameters and 95% limits on other parameters.) Combined with Planck
temperature and lensing data, Planck LFI polarization measurements lead to a
reionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with
other astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective
number of relativistic degrees of freedom and the sum of neutrino masses is
constrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005.
For LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent
with the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck
(BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We
find no evidence for isocurvature perturbations or cosmic defects. The equation
of state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big
bang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent
agreement with observations. We investigate annihilating dark matter and
deviations from standard recombination, finding no evidence for new physics.
The Planck results for base LCDM are in agreement with BAO data and with the
JLA SNe sample. However the amplitude of the fluctuations is found to be higher
than inferred from rich cluster counts and weak gravitational lensing. Apart
from these tensions, the base LCDM cosmology provides an excellent description
of the Planck CMB observations and many other astrophysical data sets.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, M. Arnaud, M. Ashdown,
  J. Aumont, C. Baccigalupi, A. J. Banday, R. B. Barreiro, J. G. Bartlett, N.
  Bartolo, E. Battaner, R. Battye, K. Benabed, A. Benoit, A. Benoit-Levy, J.-P.
  Bernard, M. Bersanelli, P. Bielewicz, J. J. Bock, A. Bonaldi, L. Bonavera, J.
  R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C. Burigana, R.
  C. Butler, E. Calabrese, J.-F. Cardoso, A. Catalano, A. Challinor, A.
  Chamballu, R.-R. Chary, H. C. Chiang, J. Chluba, P. R. Christensen, S.
  Church, D. L. Clements, S. Colombi, L. P. L. Colombo, C. Combet, A. Coulais,
  B. P. Crill, A. Curto, F. Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P.
  de Bernardis, A. de Rosa, G. de Zotti, J. Delabrouille, F.-X. Desert, E. Di
  Valentino, C. Dickinson, J. M. Diego, K. Dolag, H. Dole, S. Donzelli, O.
  Dore, M. Douspis, A. Ducout, J. Dunkley, X. Dupac, G. Efstathiou, F. Elsner,
  T. A. Ensslin, H. K. Eriksen, M. Farhang, J. Fergusson, F. Finelli, O. Forni,
  M. Frailis, A. A. Fraisse, E. Franceschi, A. Frejsel, S. Galeotta, S. Galli,
  K. Ganga, C. Gauthier, M. Gerbino, T. Ghosh, M. Giard, Y. Giraud-Heraud, E.
  Giusarma, E. Gjerlow, J. Gonzalez-Nuevo, K. M. Gorski, S. Gratton, A.
  Gregorio, A. Gruppuso, J. E. Gudmundsson, J. Hamann, F. K. Hansen, D. Hanson,
  D. L. Harrison, G. Helou, S. Henrot-Versille, C. Hernandez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  W. Hovest, Z. Huang, K. M. Huffenberger, G. Hurier, A. H. Jaffe, T. R. Jaffe,
  W. C. Jones, M. Juvela, E. Keihanen, R. Keskitalo, T. S. Kisner, R. Kneissl,
  J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A. Lahteenmaki,
  J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R. Lawrence, J. P. Leahy, R.
  Leonardi, J. Lesgourgues, F. Levrier, A. Lewis, M. Liguori, P. B. Lilje, M.
  Linden-Vornle, M. Lopez-Caniego, P. M. Lubin, J. F. Macias-Perez, G. Maggio,
  D. Maino, N. Mandolesi, A. Mangilli, A. Marchini, P. G. Martin, M.
  Martinelli, E. Martinez-Gonzalez, S. Masi, S. Matarrese, P. Mazzotta, P.
  McGehee, P. R. Meinhold, A. Melchiorri, J.-B. Melin, L. Mendes, A. Mennella,
  M. Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Deschenes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. Norgaard-Nielsen, F.
  Noviello, D. Novikov, I. Novikov, C. A. Oxborrow, F. Paci, L. Pagano, F.
  Pajot, R. Paladini, D. Paoletti, B. Partridge, F. Pasian, G. Patanchon, T. J.
  Pearson, O. Perdereau, L. Perotto, F. Perrotta, V. Pettorino, F. Piacentini,
  M. Piat, E. Pierpaoli, D. Pietrobon, S. Plaszczynski, E. Pointecouteau, G.
  Polenta, L. Popa, G. W. Pratt, G. Prezeau, S. Prunet, J.-L. Puget, J. P.
  Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C. Renault, A.
  Renzi, I. Ristorcelli, G. Rocha, C. Rosset, M. Rossetti, G. Roudier, B.
  Rouille d'Orfeuil, M. Rowan-Robinson, J. A. Rubino-Martin, B. Rusholme, N.
  Said, V. Salvatelli, L. Salvati, M. Sandri, D. Santos, M. Savelainen, G.
  Savini, D. Scott, M. D. Seiffert, P. Serra, E. P. S. Shellard, L. D. Spencer,
  M. Spinelli, V. Stolyarov, R. Stompor, R. Sudiwala, R. Sunyaev, D. Sutton,
  A.-S. Suur-Uski, J.-F. Sygnet, J. A. Tauber, L. Terenzi, L. Toffolatti, M.
  Tomasi, M. Tristram, T. Trombetti, M. Tucci, J. Tuovinen, M. Turler, G.
  Umana, L. Valenziano, J. Valiviita, B. Van Tent, P. Vielva, F. Villa, L. A.
  Wade, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A. Wilkinson, D.
  Yvon, A. Zacchei, A. Zonca","A&A 594, A13 (2016)",Physics,Physics
2016,1502.01589,1329,Planck 2015 results. XIII. Cosmological parameters,"  We present results based on full-mission Planck observations of temperature
and polarization anisotropies of the CMB. These data are consistent with the
six-parameter inflationary LCDM cosmology. From the Planck temperature and
lensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9)
km/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar
spectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured
parameters and 95% limits on other parameters.) Combined with Planck
temperature and lensing data, Planck LFI polarization measurements lead to a
reionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with
other astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective
number of relativistic degrees of freedom and the sum of neutrino masses is
constrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005.
For LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent
with the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck
(BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We
find no evidence for isocurvature perturbations or cosmic defects. The equation
of state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big
bang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent
agreement with observations. We investigate annihilating dark matter and
deviations from standard recombination, finding no evidence for new physics.
The Planck results for base LCDM are in agreement with BAO data and with the
JLA SNe sample. However the amplitude of the fluctuations is found to be higher
than inferred from rich cluster counts and weak gravitational lensing. Apart
from these tensions, the base LCDM cosmology provides an excellent description
of the Planck CMB observations and many other astrophysical data sets.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, M. Arnaud, M. Ashdown,
  J. Aumont, C. Baccigalupi, A. J. Banday, R. B. Barreiro, J. G. Bartlett, N.
  Bartolo, E. Battaner, R. Battye, K. Benabed, A. Benoit, A. Benoit-Levy, J.-P.
  Bernard, M. Bersanelli, P. Bielewicz, J. J. Bock, A. Bonaldi, L. Bonavera, J.
  R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C. Burigana, R.
  C. Butler, E. Calabrese, J.-F. Cardoso, A. Catalano, A. Challinor, A.
  Chamballu, R.-R. Chary, H. C. Chiang, J. Chluba, P. R. Christensen, S.
  Church, D. L. Clements, S. Colombi, L. P. L. Colombo, C. Combet, A. Coulais,
  B. P. Crill, A. Curto, F. Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P.
  de Bernardis, A. de Rosa, G. de Zotti, J. Delabrouille, F.-X. Desert, E. Di
  Valentino, C. Dickinson, J. M. Diego, K. Dolag, H. Dole, S. Donzelli, O.
  Dore, M. Douspis, A. Ducout, J. Dunkley, X. Dupac, G. Efstathiou, F. Elsner,
  T. A. Ensslin, H. K. Eriksen, M. Farhang, J. Fergusson, F. Finelli, O. Forni,
  M. Frailis, A. A. Fraisse, E. Franceschi, A. Frejsel, S. Galeotta, S. Galli,
  K. Ganga, C. Gauthier, M. Gerbino, T. Ghosh, M. Giard, Y. Giraud-Heraud, E.
  Giusarma, E. Gjerlow, J. Gonzalez-Nuevo, K. M. Gorski, S. Gratton, A.
  Gregorio, A. Gruppuso, J. E. Gudmundsson, J. Hamann, F. K. Hansen, D. Hanson,
  D. L. Harrison, G. Helou, S. Henrot-Versille, C. Hernandez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  W. Hovest, Z. Huang, K. M. Huffenberger, G. Hurier, A. H. Jaffe, T. R. Jaffe,
  W. C. Jones, M. Juvela, E. Keihanen, R. Keskitalo, T. S. Kisner, R. Kneissl,
  J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A. Lahteenmaki,
  J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R. Lawrence, J. P. Leahy, R.
  Leonardi, J. Lesgourgues, F. Levrier, A. Lewis, M. Liguori, P. B. Lilje, M.
  Linden-Vornle, M. Lopez-Caniego, P. M. Lubin, J. F. Macias-Perez, G. Maggio,
  D. Maino, N. Mandolesi, A. Mangilli, A. Marchini, P. G. Martin, M.
  Martinelli, E. Martinez-Gonzalez, S. Masi, S. Matarrese, P. Mazzotta, P.
  McGehee, P. R. Meinhold, A. Melchiorri, J.-B. Melin, L. Mendes, A. Mennella,
  M. Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Deschenes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. Norgaard-Nielsen, F.
  Noviello, D. Novikov, I. Novikov, C. A. Oxborrow, F. Paci, L. Pagano, F.
  Pajot, R. Paladini, D. Paoletti, B. Partridge, F. Pasian, G. Patanchon, T. J.
  Pearson, O. Perdereau, L. Perotto, F. Perrotta, V. Pettorino, F. Piacentini,
  M. Piat, E. Pierpaoli, D. Pietrobon, S. Plaszczynski, E. Pointecouteau, G.
  Polenta, L. Popa, G. W. Pratt, G. Prezeau, S. Prunet, J.-L. Puget, J. P.
  Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C. Renault, A.
  Renzi, I. Ristorcelli, G. Rocha, C. Rosset, M. Rossetti, G. Roudier, B.
  Rouille d'Orfeuil, M. Rowan-Robinson, J. A. Rubino-Martin, B. Rusholme, N.
  Said, V. Salvatelli, L. Salvati, M. Sandri, D. Santos, M. Savelainen, G.
  Savini, D. Scott, M. D. Seiffert, P. Serra, E. P. S. Shellard, L. D. Spencer,
  M. Spinelli, V. Stolyarov, R. Stompor, R. Sudiwala, R. Sunyaev, D. Sutton,
  A.-S. Suur-Uski, J.-F. Sygnet, J. A. Tauber, L. Terenzi, L. Toffolatti, M.
  Tomasi, M. Tristram, T. Trombetti, M. Tucci, J. Tuovinen, M. Turler, G.
  Umana, L. Valenziano, J. Valiviita, B. Van Tent, P. Vielva, F. Villa, L. A.
  Wade, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A. Wilkinson, D.
  Yvon, A. Zacchei, A. Zonca","A&A 594, A13 (2016)",Physics,Physics
2017,1502.01589,1142,Planck 2015 results. XIII. Cosmological parameters,"  We present results based on full-mission Planck observations of temperature
and polarization anisotropies of the CMB. These data are consistent with the
six-parameter inflationary LCDM cosmology. From the Planck temperature and
lensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9)
km/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar
spectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured
parameters and 95% limits on other parameters.) Combined with Planck
temperature and lensing data, Planck LFI polarization measurements lead to a
reionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with
other astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective
number of relativistic degrees of freedom and the sum of neutrino masses is
constrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005.
For LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent
with the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck
(BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We
find no evidence for isocurvature perturbations or cosmic defects. The equation
of state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big
bang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent
agreement with observations. We investigate annihilating dark matter and
deviations from standard recombination, finding no evidence for new physics.
The Planck results for base LCDM are in agreement with BAO data and with the
JLA SNe sample. However the amplitude of the fluctuations is found to be higher
than inferred from rich cluster counts and weak gravitational lensing. Apart
from these tensions, the base LCDM cosmology provides an excellent description
of the Planck CMB observations and many other astrophysical data sets.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, M. Arnaud, M. Ashdown,
  J. Aumont, C. Baccigalupi, A. J. Banday, R. B. Barreiro, J. G. Bartlett, N.
  Bartolo, E. Battaner, R. Battye, K. Benabed, A. Benoit, A. Benoit-Levy, J.-P.
  Bernard, M. Bersanelli, P. Bielewicz, J. J. Bock, A. Bonaldi, L. Bonavera, J.
  R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C. Burigana, R.
  C. Butler, E. Calabrese, J.-F. Cardoso, A. Catalano, A. Challinor, A.
  Chamballu, R.-R. Chary, H. C. Chiang, J. Chluba, P. R. Christensen, S.
  Church, D. L. Clements, S. Colombi, L. P. L. Colombo, C. Combet, A. Coulais,
  B. P. Crill, A. Curto, F. Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P.
  de Bernardis, A. de Rosa, G. de Zotti, J. Delabrouille, F.-X. Desert, E. Di
  Valentino, C. Dickinson, J. M. Diego, K. Dolag, H. Dole, S. Donzelli, O.
  Dore, M. Douspis, A. Ducout, J. Dunkley, X. Dupac, G. Efstathiou, F. Elsner,
  T. A. Ensslin, H. K. Eriksen, M. Farhang, J. Fergusson, F. Finelli, O. Forni,
  M. Frailis, A. A. Fraisse, E. Franceschi, A. Frejsel, S. Galeotta, S. Galli,
  K. Ganga, C. Gauthier, M. Gerbino, T. Ghosh, M. Giard, Y. Giraud-Heraud, E.
  Giusarma, E. Gjerlow, J. Gonzalez-Nuevo, K. M. Gorski, S. Gratton, A.
  Gregorio, A. Gruppuso, J. E. Gudmundsson, J. Hamann, F. K. Hansen, D. Hanson,
  D. L. Harrison, G. Helou, S. Henrot-Versille, C. Hernandez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  W. Hovest, Z. Huang, K. M. Huffenberger, G. Hurier, A. H. Jaffe, T. R. Jaffe,
  W. C. Jones, M. Juvela, E. Keihanen, R. Keskitalo, T. S. Kisner, R. Kneissl,
  J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A. Lahteenmaki,
  J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R. Lawrence, J. P. Leahy, R.
  Leonardi, J. Lesgourgues, F. Levrier, A. Lewis, M. Liguori, P. B. Lilje, M.
  Linden-Vornle, M. Lopez-Caniego, P. M. Lubin, J. F. Macias-Perez, G. Maggio,
  D. Maino, N. Mandolesi, A. Mangilli, A. Marchini, P. G. Martin, M.
  Martinelli, E. Martinez-Gonzalez, S. Masi, S. Matarrese, P. Mazzotta, P.
  McGehee, P. R. Meinhold, A. Melchiorri, J.-B. Melin, L. Mendes, A. Mennella,
  M. Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Deschenes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. Norgaard-Nielsen, F.
  Noviello, D. Novikov, I. Novikov, C. A. Oxborrow, F. Paci, L. Pagano, F.
  Pajot, R. Paladini, D. Paoletti, B. Partridge, F. Pasian, G. Patanchon, T. J.
  Pearson, O. Perdereau, L. Perotto, F. Perrotta, V. Pettorino, F. Piacentini,
  M. Piat, E. Pierpaoli, D. Pietrobon, S. Plaszczynski, E. Pointecouteau, G.
  Polenta, L. Popa, G. W. Pratt, G. Prezeau, S. Prunet, J.-L. Puget, J. P.
  Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C. Renault, A.
  Renzi, I. Ristorcelli, G. Rocha, C. Rosset, M. Rossetti, G. Roudier, B.
  Rouille d'Orfeuil, M. Rowan-Robinson, J. A. Rubino-Martin, B. Rusholme, N.
  Said, V. Salvatelli, L. Salvati, M. Sandri, D. Santos, M. Savelainen, G.
  Savini, D. Scott, M. D. Seiffert, P. Serra, E. P. S. Shellard, L. D. Spencer,
  M. Spinelli, V. Stolyarov, R. Stompor, R. Sudiwala, R. Sunyaev, D. Sutton,
  A.-S. Suur-Uski, J.-F. Sygnet, J. A. Tauber, L. Terenzi, L. Toffolatti, M.
  Tomasi, M. Tristram, T. Trombetti, M. Tucci, J. Tuovinen, M. Turler, G.
  Umana, L. Valenziano, J. Valiviita, B. Van Tent, P. Vielva, F. Villa, L. A.
  Wade, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A. Wilkinson, D.
  Yvon, A. Zacchei, A. Zonca","A&A 594, A13 (2016)",Physics,Physics
2018,1502.01589,936,Planck 2015 results. XIII. Cosmological parameters,"  We present results based on full-mission Planck observations of temperature
and polarization anisotropies of the CMB. These data are consistent with the
six-parameter inflationary LCDM cosmology. From the Planck temperature and
lensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9)
km/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar
spectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured
parameters and 95% limits on other parameters.) Combined with Planck
temperature and lensing data, Planck LFI polarization measurements lead to a
reionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with
other astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective
number of relativistic degrees of freedom and the sum of neutrino masses is
constrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005.
For LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent
with the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck
(BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We
find no evidence for isocurvature perturbations or cosmic defects. The equation
of state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big
bang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent
agreement with observations. We investigate annihilating dark matter and
deviations from standard recombination, finding no evidence for new physics.
The Planck results for base LCDM are in agreement with BAO data and with the
JLA SNe sample. However the amplitude of the fluctuations is found to be higher
than inferred from rich cluster counts and weak gravitational lensing. Apart
from these tensions, the base LCDM cosmology provides an excellent description
of the Planck CMB observations and many other astrophysical data sets.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, M. Arnaud, M. Ashdown,
  J. Aumont, C. Baccigalupi, A. J. Banday, R. B. Barreiro, J. G. Bartlett, N.
  Bartolo, E. Battaner, R. Battye, K. Benabed, A. Benoit, A. Benoit-Levy, J.-P.
  Bernard, M. Bersanelli, P. Bielewicz, J. J. Bock, A. Bonaldi, L. Bonavera, J.
  R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C. Burigana, R.
  C. Butler, E. Calabrese, J.-F. Cardoso, A. Catalano, A. Challinor, A.
  Chamballu, R.-R. Chary, H. C. Chiang, J. Chluba, P. R. Christensen, S.
  Church, D. L. Clements, S. Colombi, L. P. L. Colombo, C. Combet, A. Coulais,
  B. P. Crill, A. Curto, F. Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P.
  de Bernardis, A. de Rosa, G. de Zotti, J. Delabrouille, F.-X. Desert, E. Di
  Valentino, C. Dickinson, J. M. Diego, K. Dolag, H. Dole, S. Donzelli, O.
  Dore, M. Douspis, A. Ducout, J. Dunkley, X. Dupac, G. Efstathiou, F. Elsner,
  T. A. Ensslin, H. K. Eriksen, M. Farhang, J. Fergusson, F. Finelli, O. Forni,
  M. Frailis, A. A. Fraisse, E. Franceschi, A. Frejsel, S. Galeotta, S. Galli,
  K. Ganga, C. Gauthier, M. Gerbino, T. Ghosh, M. Giard, Y. Giraud-Heraud, E.
  Giusarma, E. Gjerlow, J. Gonzalez-Nuevo, K. M. Gorski, S. Gratton, A.
  Gregorio, A. Gruppuso, J. E. Gudmundsson, J. Hamann, F. K. Hansen, D. Hanson,
  D. L. Harrison, G. Helou, S. Henrot-Versille, C. Hernandez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  W. Hovest, Z. Huang, K. M. Huffenberger, G. Hurier, A. H. Jaffe, T. R. Jaffe,
  W. C. Jones, M. Juvela, E. Keihanen, R. Keskitalo, T. S. Kisner, R. Kneissl,
  J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A. Lahteenmaki,
  J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R. Lawrence, J. P. Leahy, R.
  Leonardi, J. Lesgourgues, F. Levrier, A. Lewis, M. Liguori, P. B. Lilje, M.
  Linden-Vornle, M. Lopez-Caniego, P. M. Lubin, J. F. Macias-Perez, G. Maggio,
  D. Maino, N. Mandolesi, A. Mangilli, A. Marchini, P. G. Martin, M.
  Martinelli, E. Martinez-Gonzalez, S. Masi, S. Matarrese, P. Mazzotta, P.
  McGehee, P. R. Meinhold, A. Melchiorri, J.-B. Melin, L. Mendes, A. Mennella,
  M. Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Deschenes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. Norgaard-Nielsen, F.
  Noviello, D. Novikov, I. Novikov, C. A. Oxborrow, F. Paci, L. Pagano, F.
  Pajot, R. Paladini, D. Paoletti, B. Partridge, F. Pasian, G. Patanchon, T. J.
  Pearson, O. Perdereau, L. Perotto, F. Perrotta, V. Pettorino, F. Piacentini,
  M. Piat, E. Pierpaoli, D. Pietrobon, S. Plaszczynski, E. Pointecouteau, G.
  Polenta, L. Popa, G. W. Pratt, G. Prezeau, S. Prunet, J.-L. Puget, J. P.
  Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C. Renault, A.
  Renzi, I. Ristorcelli, G. Rocha, C. Rosset, M. Rossetti, G. Roudier, B.
  Rouille d'Orfeuil, M. Rowan-Robinson, J. A. Rubino-Martin, B. Rusholme, N.
  Said, V. Salvatelli, L. Salvati, M. Sandri, D. Santos, M. Savelainen, G.
  Savini, D. Scott, M. D. Seiffert, P. Serra, E. P. S. Shellard, L. D. Spencer,
  M. Spinelli, V. Stolyarov, R. Stompor, R. Sudiwala, R. Sunyaev, D. Sutton,
  A.-S. Suur-Uski, J.-F. Sygnet, J. A. Tauber, L. Terenzi, L. Toffolatti, M.
  Tomasi, M. Tristram, T. Trombetti, M. Tucci, J. Tuovinen, M. Turler, G.
  Umana, L. Valenziano, J. Valiviita, B. Van Tent, P. Vielva, F. Villa, L. A.
  Wade, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A. Wilkinson, D.
  Yvon, A. Zacchei, A. Zonca","A&A 594, A13 (2016)",Physics,Physics
2019,1502.01589,528,Planck 2015 results. XIII. Cosmological parameters,"  We present results based on full-mission Planck observations of temperature
and polarization anisotropies of the CMB. These data are consistent with the
six-parameter inflationary LCDM cosmology. From the Planck temperature and
lensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9)
km/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar
spectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured
parameters and 95% limits on other parameters.) Combined with Planck
temperature and lensing data, Planck LFI polarization measurements lead to a
reionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with
other astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective
number of relativistic degrees of freedom and the sum of neutrino masses is
constrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005.
For LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent
with the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck
(BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We
find no evidence for isocurvature perturbations or cosmic defects. The equation
of state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big
bang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent
agreement with observations. We investigate annihilating dark matter and
deviations from standard recombination, finding no evidence for new physics.
The Planck results for base LCDM are in agreement with BAO data and with the
JLA SNe sample. However the amplitude of the fluctuations is found to be higher
than inferred from rich cluster counts and weak gravitational lensing. Apart
from these tensions, the base LCDM cosmology provides an excellent description
of the Planck CMB observations and many other astrophysical data sets.
","Planck Collaboration: P. A. R. Ade, N. Aghanim, M. Arnaud, M. Ashdown,
  J. Aumont, C. Baccigalupi, A. J. Banday, R. B. Barreiro, J. G. Bartlett, N.
  Bartolo, E. Battaner, R. Battye, K. Benabed, A. Benoit, A. Benoit-Levy, J.-P.
  Bernard, M. Bersanelli, P. Bielewicz, J. J. Bock, A. Bonaldi, L. Bonavera, J.
  R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C. Burigana, R.
  C. Butler, E. Calabrese, J.-F. Cardoso, A. Catalano, A. Challinor, A.
  Chamballu, R.-R. Chary, H. C. Chiang, J. Chluba, P. R. Christensen, S.
  Church, D. L. Clements, S. Colombi, L. P. L. Colombo, C. Combet, A. Coulais,
  B. P. Crill, A. Curto, F. Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P.
  de Bernardis, A. de Rosa, G. de Zotti, J. Delabrouille, F.-X. Desert, E. Di
  Valentino, C. Dickinson, J. M. Diego, K. Dolag, H. Dole, S. Donzelli, O.
  Dore, M. Douspis, A. Ducout, J. Dunkley, X. Dupac, G. Efstathiou, F. Elsner,
  T. A. Ensslin, H. K. Eriksen, M. Farhang, J. Fergusson, F. Finelli, O. Forni,
  M. Frailis, A. A. Fraisse, E. Franceschi, A. Frejsel, S. Galeotta, S. Galli,
  K. Ganga, C. Gauthier, M. Gerbino, T. Ghosh, M. Giard, Y. Giraud-Heraud, E.
  Giusarma, E. Gjerlow, J. Gonzalez-Nuevo, K. M. Gorski, S. Gratton, A.
  Gregorio, A. Gruppuso, J. E. Gudmundsson, J. Hamann, F. K. Hansen, D. Hanson,
  D. L. Harrison, G. Helou, S. Henrot-Versille, C. Hernandez-Monteagudo, D.
  Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup,
  W. Hovest, Z. Huang, K. M. Huffenberger, G. Hurier, A. H. Jaffe, T. R. Jaffe,
  W. C. Jones, M. Juvela, E. Keihanen, R. Keskitalo, T. S. Kisner, R. Kneissl,
  J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A. Lahteenmaki,
  J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R. Lawrence, J. P. Leahy, R.
  Leonardi, J. Lesgourgues, F. Levrier, A. Lewis, M. Liguori, P. B. Lilje, M.
  Linden-Vornle, M. Lopez-Caniego, P. M. Lubin, J. F. Macias-Perez, G. Maggio,
  D. Maino, N. Mandolesi, A. Mangilli, A. Marchini, P. G. Martin, M.
  Martinelli, E. Martinez-Gonzalez, S. Masi, S. Matarrese, P. Mazzotta, P.
  McGehee, P. R. Meinhold, A. Melchiorri, J.-B. Melin, L. Mendes, A. Mennella,
  M. Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Deschenes, A. Moneti, L.
  Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P.
  Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. Norgaard-Nielsen, F.
  Noviello, D. Novikov, I. Novikov, C. A. Oxborrow, F. Paci, L. Pagano, F.
  Pajot, R. Paladini, D. Paoletti, B. Partridge, F. Pasian, G. Patanchon, T. J.
  Pearson, O. Perdereau, L. Perotto, F. Perrotta, V. Pettorino, F. Piacentini,
  M. Piat, E. Pierpaoli, D. Pietrobon, S. Plaszczynski, E. Pointecouteau, G.
  Polenta, L. Popa, G. W. Pratt, G. Prezeau, S. Prunet, J.-L. Puget, J. P.
  Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C. Renault, A.
  Renzi, I. Ristorcelli, G. Rocha, C. Rosset, M. Rossetti, G. Roudier, B.
  Rouille d'Orfeuil, M. Rowan-Robinson, J. A. Rubino-Martin, B. Rusholme, N.
  Said, V. Salvatelli, L. Salvati, M. Sandri, D. Santos, M. Savelainen, G.
  Savini, D. Scott, M. D. Seiffert, P. Serra, E. P. S. Shellard, L. D. Spencer,
  M. Spinelli, V. Stolyarov, R. Stompor, R. Sudiwala, R. Sunyaev, D. Sutton,
  A.-S. Suur-Uski, J.-F. Sygnet, J. A. Tauber, L. Terenzi, L. Toffolatti, M.
  Tomasi, M. Tristram, T. Trombetti, M. Tucci, J. Tuovinen, M. Turler, G.
  Umana, L. Valenziano, J. Valiviita, B. Van Tent, P. Vielva, F. Villa, L. A.
  Wade, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A. Wilkinson, D.
  Yvon, A. Zacchei, A. Zonca","A&A 594, A13 (2016)",Physics,Physics
2016,1405.0301,500,"The automated computation of tree-level and next-to-leading order
  differential cross sections, and their matching to parton shower simulations","  We discuss the theoretical bases that underpin the automation of the
computations of tree-level and next-to-leading order cross sections, of their
matching to parton shower simulations, and of the merging of matched samples
that differ by light-parton multiplicities. We present a computer program,
MadGraph5_aMC@NLO, capable of handling all these computations -- parton-level
fixed order, shower-matched, merged -- in a unified framework whose defining
features are flexibility, high level of parallelisation, and human intervention
limited to input physics quantities. We demonstrate the potential of the
program by presenting selected phenomenological applications relevant to the
LHC and to a 1-TeV $e^+e^-$ collider. While next-to-leading order results are
restricted to QCD corrections to SM processes in the first public version, we
show that from the user viewpoint no changes have to be expected in the case of
corrections due to any given renormalisable Lagrangian, and that the
implementation of these are well under way.
","J. Alwall, R. Frederix, S. Frixione, V. Hirschi, F. Maltoni, O.
  Mattelaer, H.-S. Shao, T. Stelzer, P. Torrielli, M. Zaro",JHEP07(2014)079,Physics,Physics
2017,1405.0301,567,"The automated computation of tree-level and next-to-leading order
  differential cross sections, and their matching to parton shower simulations","  We discuss the theoretical bases that underpin the automation of the
computations of tree-level and next-to-leading order cross sections, of their
matching to parton shower simulations, and of the merging of matched samples
that differ by light-parton multiplicities. We present a computer program,
MadGraph5_aMC@NLO, capable of handling all these computations -- parton-level
fixed order, shower-matched, merged -- in a unified framework whose defining
features are flexibility, high level of parallelisation, and human intervention
limited to input physics quantities. We demonstrate the potential of the
program by presenting selected phenomenological applications relevant to the
LHC and to a 1-TeV $e^+e^-$ collider. While next-to-leading order results are
restricted to QCD corrections to SM processes in the first public version, we
show that from the user viewpoint no changes have to be expected in the case of
corrections due to any given renormalisable Lagrangian, and that the
implementation of these are well under way.
","J. Alwall, R. Frederix, S. Frixione, V. Hirschi, F. Maltoni, O.
  Mattelaer, H.-S. Shao, T. Stelzer, P. Torrielli, M. Zaro",JHEP07(2014)079,Physics,Physics
2018,1405.0301,594,"The automated computation of tree-level and next-to-leading order
  differential cross sections, and their matching to parton shower simulations","  We discuss the theoretical bases that underpin the automation of the
computations of tree-level and next-to-leading order cross sections, of their
matching to parton shower simulations, and of the merging of matched samples
that differ by light-parton multiplicities. We present a computer program,
MadGraph5_aMC@NLO, capable of handling all these computations -- parton-level
fixed order, shower-matched, merged -- in a unified framework whose defining
features are flexibility, high level of parallelisation, and human intervention
limited to input physics quantities. We demonstrate the potential of the
program by presenting selected phenomenological applications relevant to the
LHC and to a 1-TeV $e^+e^-$ collider. While next-to-leading order results are
restricted to QCD corrections to SM processes in the first public version, we
show that from the user viewpoint no changes have to be expected in the case of
corrections due to any given renormalisable Lagrangian, and that the
implementation of these are well under way.
","J. Alwall, R. Frederix, S. Frixione, V. Hirschi, F. Maltoni, O.
  Mattelaer, H.-S. Shao, T. Stelzer, P. Torrielli, M. Zaro",JHEP07(2014)079,Physics,Physics
2020,1405.0301,62,"The automated computation of tree-level and next-to-leading order
  differential cross sections, and their matching to parton shower simulations","  We discuss the theoretical bases that underpin the automation of the
computations of tree-level and next-to-leading order cross sections, of their
matching to parton shower simulations, and of the merging of matched samples
that differ by light-parton multiplicities. We present a computer program,
MadGraph5_aMC@NLO, capable of handling all these computations -- parton-level
fixed order, shower-matched, merged -- in a unified framework whose defining
features are flexibility, high level of parallelisation, and human intervention
limited to input physics quantities. We demonstrate the potential of the
program by presenting selected phenomenological applications relevant to the
LHC and to a 1-TeV $e^+e^-$ collider. While next-to-leading order results are
restricted to QCD corrections to SM processes in the first public version, we
show that from the user viewpoint no changes have to be expected in the case of
corrections due to any given renormalisable Lagrangian, and that the
implementation of these are well under way.
","J. Alwall, R. Frederix, S. Frixione, V. Hirschi, F. Maltoni, O.
  Mattelaer, H.-S. Shao, T. Stelzer, P. Torrielli, M. Zaro",JHEP07(2014)079,Physics,Physics
2019,1807.06209,1477,Planck 2018 results. VI. Cosmological parameters,"  We present cosmological parameter results from the final full-mission Planck
measurements of the CMB anisotropies. We find good consistency with the
standard spatially-flat 6-parameter $\Lambda$CDM cosmology having a power-law
spectrum of adiabatic scalar perturbations (denoted ""base $\Lambda$CDM"" in this
paper), from polarization, temperature, and lensing, separately and in
combination. A combined analysis gives dark matter density $\Omega_c h^2 =
0.120\pm 0.001$, baryon density $\Omega_b h^2 = 0.0224\pm 0.0001$, scalar
spectral index $n_s = 0.965\pm 0.004$, and optical depth $\tau = 0.054\pm
0.007$ (in this abstract we quote $68\,\%$ confidence regions on measured
parameters and $95\,\%$ on upper limits). The angular acoustic scale is
measured to $0.03\,\%$ precision, with $100\theta_*=1.0411\pm 0.0003$. These
results are only weakly dependent on the cosmological model and remain stable,
with somewhat increased errors, in many commonly considered extensions.
Assuming the base-$\Lambda$CDM cosmology, the inferred late-Universe parameters
are: Hubble constant $H_0 = (67.4\pm 0.5)$km/s/Mpc; matter density parameter
$\Omega_m = 0.315\pm 0.007$; and matter fluctuation amplitude $\sigma_8 =
0.811\pm 0.006$. We find no compelling evidence for extensions to the
base-$\Lambda$CDM model. Combining with BAO we constrain the effective extra
relativistic degrees of freedom to be $N_{\rm eff} = 2.99\pm 0.17$, and the
neutrino mass is tightly constrained to $\sum m_\nu< 0.12$eV. The CMB spectra
continue to prefer higher lensing amplitudes than predicted in base
-$\Lambda$CDM at over $2\,\sigma$, which pulls some parameters that affect the
lensing amplitude away from the base-$\Lambda$CDM model; however, this is not
supported by the lensing reconstruction or (in models that also change the
background geometry) BAO data. (Abridged)
","Planck Collaboration: N. Aghanim, Y. Akrami, M. Ashdown, J. Aumont, C.
  Baccigalupi, M. Ballardini, A. J. Banday, R. B. Barreiro, N. Bartolo, S.
  Basak, R. Battye, K. Benabed, J.-P. Bernard, M. Bersanelli, P. Bielewicz, J.
  J. Bock, J. R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C.
  Burigana, R. C. Butler, E. Calabrese, J.-F. Cardoso, J. Carron, A. Challinor,
  H. C. Chiang, J. Chluba, L. P. L. Colombo, C. Combet, D. Contreras, B. P.
  Crill, F. Cuttaia, P. de Bernardis, G. de Zotti, J. Delabrouille, J.-M.
  Delouis, E. Di Valentino, J. M. Diego, O. Dor\'e, M. Douspis, A. Ducout, X.
  Dupac, S. Dusini, G. Efstathiou, F. Elsner, T. A. En{\ss}lin, H. K. Eriksen,
  Y. Fantaye, M. Farhang, J. Fergusson, R. Fernandez-Cobos, F. Finelli, F.
  Forastieri, M. Frailis, A. A. Fraisse, E. Franceschi, A. Frolov, S. Galeotta,
  S. Galli, K. Ganga, R. T. G\'enova-Santos, M. Gerbino, T. Ghosh, J.
  Gonz\'alez-Nuevo, K. M. G\'orski, S. Gratton, A. Gruppuso, J. E. Gudmundsson,
  J. Hamann, W. Handley, F. K. Hansen, D. Herranz, S. R. Hildebrandt, E. Hivon,
  Z. Huang, A. H. Jaffe, W. C. Jones, A. Karakci, E. Keih\""anen, R. Keskitalo,
  K. Kiiveri, J. Kim, T. S. Kisner, L. Knox, N. Krachmalnicoff, M. Kunz, H.
  Kurki-Suonio, G. Lagache, J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R.
  Lawrence, M. Le Jeune, P. Lemos, J. Lesgourgues, F. Levrier, A. Lewis, M.
  Liguori, P. B. Lilje, M. Lilley, V. Lindholm, M. L\'opez-Caniego, P. M.
  Lubin, Y.-Z. Ma, J. F. Mac\'ias-P\'erez, G. Maggio, D. Maino, N. Mandolesi,
  A. Mangilli, A. Marcos-Caballero, M. Maris, P. G. Martin, M. Martinelli, E.
  Mart\'inez-Gonz\'alez, S. Matarrese, N. Mauri, J. D. McEwen, P. R. Meinhold,
  A. Melchiorri, A. Mennella, M. Migliaccio, M. Millea, S. Mitra, M.-A.
  Miville-Desch\^enes, D. Molinari, L. Montier, G. Morgante, A. Moss, P.
  Natoli, H. U. N{\o}rgaard-Nielsen, L. Pagano, D. Paoletti, B. Partridge, G.
  Patanchon, H. V. Peiris, F. Perrotta, V. Pettorino, F. Piacentini, L.
  Polastri, G. Polenta, J.-L. Puget, J. P. Rachen, M. Reinecke, M. Remazeilles,
  A. Renzi, G. Rocha, C. Rosset, G. Roudier, J. A. Rubi\~no-Mart\'in, B.
  Ruiz-Granados, L. Salvati, M. Sandri, M. Savelainen, D. Scott, E. P. S.
  Shellard, C. Sirignano, G. Sirri, L. D. Spencer, R. Sunyaev, A.-S. Suur-Uski,
  J. A. Tauber, D. Tavagnacco, M. Tenti, L. Toffolatti, M. Tomasi, T.
  Trombetti, L. Valenziano, J. Valiviita, B. Van Tent, L. Vibert, P. Vielva, F.
  Villa, N. Vittorio, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A.
  Zacchei, A. Zonca","A&A 641, A6 (2020)",Physics,Physics
2020,1807.06209,253,Planck 2018 results. VI. Cosmological parameters,"  We present cosmological parameter results from the final full-mission Planck
measurements of the CMB anisotropies. We find good consistency with the
standard spatially-flat 6-parameter $\Lambda$CDM cosmology having a power-law
spectrum of adiabatic scalar perturbations (denoted ""base $\Lambda$CDM"" in this
paper), from polarization, temperature, and lensing, separately and in
combination. A combined analysis gives dark matter density $\Omega_c h^2 =
0.120\pm 0.001$, baryon density $\Omega_b h^2 = 0.0224\pm 0.0001$, scalar
spectral index $n_s = 0.965\pm 0.004$, and optical depth $\tau = 0.054\pm
0.007$ (in this abstract we quote $68\,\%$ confidence regions on measured
parameters and $95\,\%$ on upper limits). The angular acoustic scale is
measured to $0.03\,\%$ precision, with $100\theta_*=1.0411\pm 0.0003$. These
results are only weakly dependent on the cosmological model and remain stable,
with somewhat increased errors, in many commonly considered extensions.
Assuming the base-$\Lambda$CDM cosmology, the inferred late-Universe parameters
are: Hubble constant $H_0 = (67.4\pm 0.5)$km/s/Mpc; matter density parameter
$\Omega_m = 0.315\pm 0.007$; and matter fluctuation amplitude $\sigma_8 =
0.811\pm 0.006$. We find no compelling evidence for extensions to the
base-$\Lambda$CDM model. Combining with BAO we constrain the effective extra
relativistic degrees of freedom to be $N_{\rm eff} = 2.99\pm 0.17$, and the
neutrino mass is tightly constrained to $\sum m_\nu< 0.12$eV. The CMB spectra
continue to prefer higher lensing amplitudes than predicted in base
-$\Lambda$CDM at over $2\,\sigma$, which pulls some parameters that affect the
lensing amplitude away from the base-$\Lambda$CDM model; however, this is not
supported by the lensing reconstruction or (in models that also change the
background geometry) BAO data. (Abridged)
","Planck Collaboration: N. Aghanim, Y. Akrami, M. Ashdown, J. Aumont, C.
  Baccigalupi, M. Ballardini, A. J. Banday, R. B. Barreiro, N. Bartolo, S.
  Basak, R. Battye, K. Benabed, J.-P. Bernard, M. Bersanelli, P. Bielewicz, J.
  J. Bock, J. R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C.
  Burigana, R. C. Butler, E. Calabrese, J.-F. Cardoso, J. Carron, A. Challinor,
  H. C. Chiang, J. Chluba, L. P. L. Colombo, C. Combet, D. Contreras, B. P.
  Crill, F. Cuttaia, P. de Bernardis, G. de Zotti, J. Delabrouille, J.-M.
  Delouis, E. Di Valentino, J. M. Diego, O. Dor\'e, M. Douspis, A. Ducout, X.
  Dupac, S. Dusini, G. Efstathiou, F. Elsner, T. A. En{\ss}lin, H. K. Eriksen,
  Y. Fantaye, M. Farhang, J. Fergusson, R. Fernandez-Cobos, F. Finelli, F.
  Forastieri, M. Frailis, A. A. Fraisse, E. Franceschi, A. Frolov, S. Galeotta,
  S. Galli, K. Ganga, R. T. G\'enova-Santos, M. Gerbino, T. Ghosh, J.
  Gonz\'alez-Nuevo, K. M. G\'orski, S. Gratton, A. Gruppuso, J. E. Gudmundsson,
  J. Hamann, W. Handley, F. K. Hansen, D. Herranz, S. R. Hildebrandt, E. Hivon,
  Z. Huang, A. H. Jaffe, W. C. Jones, A. Karakci, E. Keih\""anen, R. Keskitalo,
  K. Kiiveri, J. Kim, T. S. Kisner, L. Knox, N. Krachmalnicoff, M. Kunz, H.
  Kurki-Suonio, G. Lagache, J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R.
  Lawrence, M. Le Jeune, P. Lemos, J. Lesgourgues, F. Levrier, A. Lewis, M.
  Liguori, P. B. Lilje, M. Lilley, V. Lindholm, M. L\'opez-Caniego, P. M.
  Lubin, Y.-Z. Ma, J. F. Mac\'ias-P\'erez, G. Maggio, D. Maino, N. Mandolesi,
  A. Mangilli, A. Marcos-Caballero, M. Maris, P. G. Martin, M. Martinelli, E.
  Mart\'inez-Gonz\'alez, S. Matarrese, N. Mauri, J. D. McEwen, P. R. Meinhold,
  A. Melchiorri, A. Mennella, M. Migliaccio, M. Millea, S. Mitra, M.-A.
  Miville-Desch\^enes, D. Molinari, L. Montier, G. Morgante, A. Moss, P.
  Natoli, H. U. N{\o}rgaard-Nielsen, L. Pagano, D. Paoletti, B. Partridge, G.
  Patanchon, H. V. Peiris, F. Perrotta, V. Pettorino, F. Piacentini, L.
  Polastri, G. Polenta, J.-L. Puget, J. P. Rachen, M. Reinecke, M. Remazeilles,
  A. Renzi, G. Rocha, C. Rosset, G. Roudier, J. A. Rubi\~no-Mart\'in, B.
  Ruiz-Granados, L. Salvati, M. Sandri, M. Savelainen, D. Scott, E. P. S.
  Shellard, C. Sirignano, G. Sirri, L. D. Spencer, R. Sunyaev, A.-S. Suur-Uski,
  J. A. Tauber, D. Tavagnacco, M. Tenti, L. Toffolatti, M. Tomasi, T.
  Trombetti, L. Valenziano, J. Valiviita, B. Van Tent, L. Vibert, P. Vielva, F.
  Villa, N. Vittorio, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A.
  Zacchei, A. Zonca","A&A 641, A6 (2020)",Physics,Physics
2020,1412.6980,75,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Physics,"Physics,Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
1997,q-alg/9602031,15,Central Extension of the Yangian Double,"  Central extension $\DYg$ of the Double of the Yangian is defined for a simple
Lie algebra ${\bf g}$ with complete proof for ${\bf g} =sl_2$. Basic
representations and intertwining operators are constructed for $\DY2$.
",S.M. Khoroshkin,,Mathematics,Mathematics
1997,q-alg/9702002,12,"Elliptic algebra $A_{q,p}(\hat{sl_2})$ in the scaling limit","  The scaling limit $A_{\hbar,\eta}(\hat{sl_2})$ of the elliptic algebra
$A_{q,p}(\hat{sl_2})$ is investigated. The limiting algebra is defined in terms
of a continuous family of generators being Fourier harmonics of Gauss
coordinates of the $L$-operator. Ding-Frenkel isomorphism between
$L$-operator's and current descriptions of the algebra
$A_{\hbar,\eta}(\hat{sl_2})$ is established and is identified with the Riemann
problem on a strip. The representations, coalgebraic structure and intertwining
operators of the algebra are studied.
","S. Khoroshkin, D. Lebedev, S. Pakuliak",,Mathematics,Mathematics
1998,q-alg/9709040,22,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
1999,q-alg/9709040,25,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
2000,q-alg/9709040,31,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
2001,q-alg/9709040,31,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
2002,q-alg/9709040,37,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
2003,q-alg/9709040,41,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
2004,q-alg/9709040,24,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
2005,q-alg/9709040,25,"Deformation quantization of Poisson manifolds, I","  I prove that every finite-dimensional Poisson manifold X admits a canonical
deformation quantization. Informally, it means that the set of equivalence
classes of associative algebras close to the algebra of functions on X is in
one-to-one correspondence with the set of equivalence classes of Poisson
structures on X modulo diffeomorphisms. In fact, a more general statement is
proven (""Formality conjecture""), relating the Lie superalgebra of polyvector
fields on X and the Hochschild complex of the algebra of functions on X.
Coefficients in explicit formulas for the deformed product can be interpreted
as correlators in a topological open string theory, although I do not use
explicitly the language of functional integrals. One of corollaries is a
justification of the orbit method in the representation theory.
",Maxim Kontsevich,"Lett.Math.Phys.66:157-216,2003",Mathematics,Mathematics
1998,q-alg/9712029,15,Quasi-Hopf twistors for elliptic quantum groups,"  The Yang-Baxter equation admits two classes of elliptic solutions, the vertex
type and the face type. On the basis of these solutions, two types of elliptic
quantum groups have been introduced (Foda et al., Felder). Fronsdal made a
penetrating observation that both of them are quasi-Hopf algebras, obtained by
twisting the standard quantum affine algebra U_q(g). In this paper we present
an explicit formula for the twistors in the form of an infinite product of the
universal R matrix of U_q(g). We also prove the shifted cocycle condition for
the twistors, thereby completing Fronsdal's findings.
  This construction entails that, for generic values of the deformation
parameters, representation theory for U_q(g) carries over to the elliptic
algebras, including such objects as evaluation modules, highest weight modules
and vertex operators. In particular, we confirm the conjectures of Foda et al.
concerning the elliptic algebra A_{q,p}(^sl_2).
","M. Jimbo, H. Konno, S. Odake and J. Shiraishi",Transformation Groups 4 (1999) 303-327,Mathematics,Mathematics
1998,hep-th/9711162,11,Noncommutative Geometry and Matrix Theory: Compactification on Tori,"  We study toroidal compactification of Matrix theory, using ideas and results
of non-commutative geometry. We generalize this to compactification on the
noncommutative torus, explain the classification of these backgrounds, and
argue that they correspond in supergravity to tori with constant background
three-form tensor field. The paper includes an introduction for mathematicians
to the IKKT formulation of Matrix theory and its relation to the BFSS Matrix
theory.
","Alain Connes, Michael R. Douglas, Albert Schwarz","JHEP 9802:003,1998",Mathematics,Mathematics
2001,hep-th/9711162,19,Noncommutative Geometry and Matrix Theory: Compactification on Tori,"  We study toroidal compactification of Matrix theory, using ideas and results
of non-commutative geometry. We generalize this to compactification on the
noncommutative torus, explain the classification of these backgrounds, and
argue that they correspond in supergravity to tori with constant background
three-form tensor field. The paper includes an introduction for mathematicians
to the IKKT formulation of Matrix theory and its relation to the BFSS Matrix
theory.
","Alain Connes, Michael R. Douglas, Albert Schwarz","JHEP 9802:003,1998",Mathematics,Mathematics
2002,hep-th/9711162,16,Noncommutative Geometry and Matrix Theory: Compactification on Tori,"  We study toroidal compactification of Matrix theory, using ideas and results
of non-commutative geometry. We generalize this to compactification on the
noncommutative torus, explain the classification of these backgrounds, and
argue that they correspond in supergravity to tori with constant background
three-form tensor field. The paper includes an introduction for mathematicians
to the IKKT formulation of Matrix theory and its relation to the BFSS Matrix
theory.
","Alain Connes, Michael R. Douglas, Albert Schwarz","JHEP 9802:003,1998",Mathematics,Mathematics
1999,math/9906120,17,Discrete orthogonal polynomial ensembles and the Plancherel measure,"  We consider discrete orthogonal polynomial ensembles which are discrete
analogues of the orthogonal polynomial ensembles in random matrix theory. These
ensembles occur in certain problems in combinatorial probability and can be
thought of as probability measures on partitions. The Meixner ensemble is
related to a two-dimensional directed growth model, and the Charlier ensemble
is related to the lengths of weakly increasing subsequences in random words.
The Krawtchouk ensemble occurs in connection with zig-zag paths in random
domino tilings of the Aztec diamond, and also in a certain simplified directed
first-passage percolation model. We use the Charlier ensemble to investigate
the asymptotics of weakly increasing subsequences in random words and to prove
a conjecture of Tracy and Widom. As a limit of the Meixner ensemble or the
Charlier ensemble we obtain the Plancherel measure on partitions, and using
this we prove a conjecture of Baik, Deift and Johansson that under the
Plancherel measure, the distribution of the lengths of the first k rows in the
partition, appropriately scaled, converges to the asymptotic joint distribution
for the k largest eigenvalues of a random matrix from the Gaussian Unitary
Ensemble. In this problem a certain discrete kernel, which we call the discrete
Bessel kernel, plays an important role.
",Kurt Johansson,"Ann. of Math. (2) 153 (2001), no. 2, 259--296",Mathematics,Mathematics
1999,math/9903176,16,Random Matrices and Random Permutations,"  We prove the conjecture of Baik, Deift, and Johansson which says that with
respect to the Plancherel measure on the set of partitions of $n$, the 1st,
2nd, and so on, rows behave, suitably scaled, like the 1st, 2nd, and so on,
eigenvalues of a Gaussian random Hermitian matrix as $n$ goes to infinity. Our
proof is based on an interplay between maps on surfaces and ramified coverings
of the sphere. We also establish a connection of this problem with intersection
theory on the moduli spaces of curves.
",Andrei Okounkov,,Mathematics,Mathematics
2000,hep-th/9908142,20,String Theory and Noncommutative Geometry,"  We extend earlier ideas about the appearance of noncommutative geometry in
string theory with a nonzero B-field. We identify a limit in which the entire
string dynamics is described by a minimally coupled (supersymmetric) gauge
theory on a noncommutative space, and discuss the corrections away from this
limit. Our analysis leads us to an equivalence between ordinary gauge fields
and noncommutative gauge fields, which is realized by a change of variables
that can be described explicitly. This change of variables is checked by
comparing the ordinary Dirac-Born-Infeld theory with its noncommutative
counterpart. We obtain a new perspective on noncommutative gauge theory on a
torus, its T-duality, and Morita equivalence. We also discuss the D0/D4 system,
the relation to M-theory in DLCQ, and a possible noncommutative version of the
six-dimensional (2,0) theory.
",Nathan Seiberg and Edward Witten,"JHEP 9909:032,1999",Mathematics,"Physics,Mathematics"
2001,hep-th/9908142,24,String Theory and Noncommutative Geometry,"  We extend earlier ideas about the appearance of noncommutative geometry in
string theory with a nonzero B-field. We identify a limit in which the entire
string dynamics is described by a minimally coupled (supersymmetric) gauge
theory on a noncommutative space, and discuss the corrections away from this
limit. Our analysis leads us to an equivalence between ordinary gauge fields
and noncommutative gauge fields, which is realized by a change of variables
that can be described explicitly. This change of variables is checked by
comparing the ordinary Dirac-Born-Infeld theory with its noncommutative
counterpart. We obtain a new perspective on noncommutative gauge theory on a
torus, its T-duality, and Morita equivalence. We also discuss the D0/D4 system,
the relation to M-theory in DLCQ, and a possible noncommutative version of the
six-dimensional (2,0) theory.
",Nathan Seiberg and Edward Witten,"JHEP 9909:032,1999",Mathematics,"Physics,Mathematics"
2002,hep-th/9908142,16,String Theory and Noncommutative Geometry,"  We extend earlier ideas about the appearance of noncommutative geometry in
string theory with a nonzero B-field. We identify a limit in which the entire
string dynamics is described by a minimally coupled (supersymmetric) gauge
theory on a noncommutative space, and discuss the corrections away from this
limit. Our analysis leads us to an equivalence between ordinary gauge fields
and noncommutative gauge fields, which is realized by a change of variables
that can be described explicitly. This change of variables is checked by
comparing the ordinary Dirac-Born-Infeld theory with its noncommutative
counterpart. We obtain a new perspective on noncommutative gauge theory on a
torus, its T-duality, and Morita equivalence. We also discuss the D0/D4 system,
the relation to M-theory in DLCQ, and a possible noncommutative version of the
six-dimensional (2,0) theory.
",Nathan Seiberg and Edward Witten,"JHEP 9909:032,1999",Mathematics,Mathematics
2000,hep-th/9606040,18,Mirror Symmetry is T-Duality,"  It is argued that every Calabi-Yau manifold $X$ with a mirror $Y$ admits a
family of supersymmetric toroidal 3-cycles. Moreover the moduli space of such
cycles together with their flat connections is precisely the space $Y$. The
mirror transformation is equivalent to T-duality on the 3-cycles. The geometry
of moduli space is addressed in a general framework. Several examples are
discussed.
","Andrew Strominger, Shing-Tung Yau, and Eric Zaslow","Nucl.Phys.B479:243-259,1996",Mathematics,Mathematics
2003,math/0209343,16,Conformal restriction: the chordal case,"  We characterize and describe all random subsets $K$ of a given simply
connected planar domain (the upper half-plane $\H$, say) which satisfy the
``conformal restriction'' property, i.e., $K$ connects two fixed boundary
points (0 and $\infty$, say) and the law of $K$ conditioned to remain in a
simply connected open subset $D$ of $\H$ is identical to that of $\Phi(K)$,
where $\Phi$ is a conformal map from $\H$ onto $D$ with $\Phi(0)=0$ and
$\Phi(\infty)=\infty$. The construction of this family relies on the stochastic
Loewner evolution (SLE) processes with parameter $\kappa \le 8/3$ and on their
distortion under conformal maps. We show in particular that SLE(8/3) is the
only random simple curve satisfying conformal restriction and relate it to the
outer boundaries of planar Brownian motion and SLE(6).
","Gregory Lawler, Oded Schramm, Wendelin Werner","J.Am.Math.Soc.16:917-955,2003",Mathematics,Mathematics
2003,math/0101147,15,"Gromov-Witten theory, Hurwitz numbers, and Matrix models, I","  The main goal of the paper is to present a new approach via Hurwitz numbers
to Kontsevich's combinatorial/matrix model for the intersection theory of the
moduli space of curves. A secondary goal is to present an exposition of the
circle of ideas involved: Hurwitz numbers, Gromov-Witten theory of the
projective line, matrix integrals, and the theory of random trees. Further
topics will be treated in a sequel.
",Andrei Okounkov and Rahul Pandharipande,,Mathematics,Mathematics
2004,hep-th/9812127,17,M-Theory and Topological Strings--II,"  It is shown how the topological string amplitudes encode the BPS structure of
wrapped M2 branes in M-theory compactification on Calabi-Yau threefolds. This
in turn is related to a twisted supersymmetric index in 5 dimensions which
receives contribution only from BPS states. The spin dependence of BPS states
in 5 dimensions is captured by the string coupling constant dependence of
topological string amplitudes.
",Rajesh Gopakumar and Cumrun Vafa,,Mathematics,Mathematics
2004,math/0312397,17,"On Simple Characterisations of Sheffer psi- polynomials and Related
  Propositions of the Calculus of Sequences","  A calculus of sequences started in 1936 opened the way for future extensions
of umbral calculus in its finite operator form. Because of historically
established notation we call it the psi-calculus.It appears in parts to be
almost automatic extension of the standard classical finite operator calculus.
",A. K. Kwasniewski,"Bull. Soc. Sci. Lett. Lodz Ser. Rech. Deform. 52, Ser. Rech.
  Deform. 36 (2002) pp.45-65",Mathematics,"Mathematics,Computer Science"
2005,math/0211159,31,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2006,math/0211159,39,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2007,math/0211159,70,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2008,math/0211159,74,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2009,math/0211159,58,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2010,math/0211159,70,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2011,math/0211159,75,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2012,math/0211159,55,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2013,math/0211159,60,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2014,math/0211159,73,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2015,math/0211159,51,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2016,math/0211159,53,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2017,math/0211159,66,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2018,math/0211159,62,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2019,math/0211159,55,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2020,math/0211159,12,The entropy formula for the Ricci flow and its geometric applications,"  We present a monotonic expression for the Ricci flow, valid in all dimensions
and without curvature assumptions. It is interpreted as an entropy for a
certain canonical ensemble. Several geometric applications are given. In
particular, (1) Ricci flow, considered on the space of riemannian metrics
modulo diffeomorphism and scaling, has no nontrivial periodic orbits (that is,
other than fixed points); (2) In a region, where singularity is forming in
finite time, the injectivity radius is controlled by the curvature; (3) Ricci
flow can not quickly turn an almost euclidean region into a very curved one, no
matter what happens far away. We also verify several assertions related to
Richard Hamilton's program for the proof of Thurston geometrization conjecture
for closed three-manifolds, and give a sketch of an eclectic proof of this
conjecture, making use of earlier results on collapsing with local lower
curvature bound.
",Grisha Perelman,,Mathematics,Mathematics
2005,math/0401221,26,Generalized complex geometry,"  Generalized complex geometry, as developed by Hitchin, contains complex and
symplectic geometry as its extremal special cases. In this thesis, we explore
novel phenomena exhibited by this geometry, such as the natural action of a
B-field. We provide new examples, including some on manifolds admitting no
known complex or symplectic structure. We prove a generalized Darboux theorem
which yields a local normal form for the geometry. We show that there is an
elliptic deformation theory and establish the existence of a Kuranishi moduli
space.
  We then define the concept of a generalized Kahler manifold. We prove that
generalized Kahler geometry is equivalent to a bi-Hermitian geometry with
torsion first discovered by physicists. We then use this result to solve an
outstanding problem in 4-dimensional bi-Hermitian geometry: we prove that there
exists a Riemannian metric on the complex projective plane which admits exactly
two distinct Hermitian complex structures with equal orientation.
  Finally, we introduce the concept of generalized complex submanifold, and
show that such sub-objects correspond to D-branes in the topological A- and
B-models of string theory.
",Marco Gualtieri,,Mathematics,Mathematics
2006,math/0401221,29,Generalized complex geometry,"  Generalized complex geometry, as developed by Hitchin, contains complex and
symplectic geometry as its extremal special cases. In this thesis, we explore
novel phenomena exhibited by this geometry, such as the natural action of a
B-field. We provide new examples, including some on manifolds admitting no
known complex or symplectic structure. We prove a generalized Darboux theorem
which yields a local normal form for the geometry. We show that there is an
elliptic deformation theory and establish the existence of a Kuranishi moduli
space.
  We then define the concept of a generalized Kahler manifold. We prove that
generalized Kahler geometry is equivalent to a bi-Hermitian geometry with
torsion first discovered by physicists. We then use this result to solve an
outstanding problem in 4-dimensional bi-Hermitian geometry: we prove that there
exists a Riemannian metric on the complex projective plane which admits exactly
two distinct Hermitian complex structures with equal orientation.
  Finally, we introduce the concept of generalized complex submanifold, and
show that such sub-objects correspond to D-branes in the topological A- and
B-models of string theory.
",Marco Gualtieri,,Mathematics,Mathematics
2007,math/0401221,28,Generalized complex geometry,"  Generalized complex geometry, as developed by Hitchin, contains complex and
symplectic geometry as its extremal special cases. In this thesis, we explore
novel phenomena exhibited by this geometry, such as the natural action of a
B-field. We provide new examples, including some on manifolds admitting no
known complex or symplectic structure. We prove a generalized Darboux theorem
which yields a local normal form for the geometry. We show that there is an
elliptic deformation theory and establish the existence of a Kuranishi moduli
space.
  We then define the concept of a generalized Kahler manifold. We prove that
generalized Kahler geometry is equivalent to a bi-Hermitian geometry with
torsion first discovered by physicists. We then use this result to solve an
outstanding problem in 4-dimensional bi-Hermitian geometry: we prove that there
exists a Riemannian metric on the complex projective plane which admits exactly
two distinct Hermitian complex structures with equal orientation.
  Finally, we introduce the concept of generalized complex submanifold, and
show that such sub-objects correspond to D-branes in the topological A- and
B-models of string theory.
",Marco Gualtieri,,Mathematics,Mathematics
2006,math/0303109,27,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2007,math/0303109,40,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2008,math/0303109,38,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2009,math/0303109,27,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2010,math/0303109,44,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2012,math/0303109,36,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2014,math/0303109,39,Ricci flow with surgery on three-manifolds,"  This is a technical paper, which is a continuation of math.DG/0211159. Here
we construct Ricci flow with surgeries and verify most of the assertions, made
in section 13 of that e-print; the exceptions are (1) the statement that
manifolds that can collapse with local lower bound on sectional curvature are
graph manifolds - this is deferred to a separate paper, since the proof has
nothing to do with the Ricci flow, and (2) the claim on the lower bound for the
volume of maximal horns and the smoothness of solutions from some time on,
which turned out to be unjustified and, on the other hand, irrelevant for the
other conclusions.
",Grisha Perelman,,Mathematics,Mathematics
2008,math/0610203,35,Existence of minimal models for varieties of log general type,"  We prove that the canonical ring of a smooth projective variety is finitely
generated.
","Caucher Birkar, Paolo Cascini, Christopher D. Hacon, James McKernan",,Mathematics,Mathematics
2009,0811.2435,42,"Stability structures, motivic Donaldson-Thomas invariants and cluster
  transformations","  We define new invariants of 3d Calabi-Yau categories endowed with a stability
structure. Intuitively, they count the number of semistable objects with fixed
class in the K-theory of the category (""number of BPS states with given charge""
in physics language). Formally, our motivic DT-invariants are elements of
quantum tori over a version of the Grothendieck ring of varieties over the
ground field. Via the quasi-classical limit ""as the motive of affine line
approaches to 1"" we obtain numerical DT-invariants which are closely related to
those introduced by Behrend. We study some properties of both motivic and
numerical DT-invariants including the wall-crossing formulas and integrality.
We discuss the relationship with the mathematical works (in the
non-triangulated case) of Joyce, Bridgeland and Toledano-Laredo, as well as
with works of physicists on Seiberg-Witten model (string junctions),
classification of N=2 supersymmetric theories (Cecotti-Vafa) and structure of
the moduli space of vector multiplets. Relating the theory of 3d Calabi-Yau
categories with distinguished set of generators (called cluster collection)
with the theory of quivers with potential we found the connection with cluster
transformations and cluster varieties (both classical and quantum).
","Maxim Kontsevich, Yan Soibelman",,Mathematics,Mathematics
2010,0811.2435,35,"Stability structures, motivic Donaldson-Thomas invariants and cluster
  transformations","  We define new invariants of 3d Calabi-Yau categories endowed with a stability
structure. Intuitively, they count the number of semistable objects with fixed
class in the K-theory of the category (""number of BPS states with given charge""
in physics language). Formally, our motivic DT-invariants are elements of
quantum tori over a version of the Grothendieck ring of varieties over the
ground field. Via the quasi-classical limit ""as the motive of affine line
approaches to 1"" we obtain numerical DT-invariants which are closely related to
those introduced by Behrend. We study some properties of both motivic and
numerical DT-invariants including the wall-crossing formulas and integrality.
We discuss the relationship with the mathematical works (in the
non-triangulated case) of Joyce, Bridgeland and Toledano-Laredo, as well as
with works of physicists on Seiberg-Witten model (string junctions),
classification of N=2 supersymmetric theories (Cecotti-Vafa) and structure of
the moduli space of vector multiplets. Relating the theory of 3d Calabi-Yau
categories with distinguished set of generators (called cluster collection)
with the theory of quivers with potential we found the connection with cluster
transformations and cluster varieties (both classical and quantum).
","Maxim Kontsevich, Yan Soibelman",,Mathematics,Mathematics
2011,0811.2435,49,"Stability structures, motivic Donaldson-Thomas invariants and cluster
  transformations","  We define new invariants of 3d Calabi-Yau categories endowed with a stability
structure. Intuitively, they count the number of semistable objects with fixed
class in the K-theory of the category (""number of BPS states with given charge""
in physics language). Formally, our motivic DT-invariants are elements of
quantum tori over a version of the Grothendieck ring of varieties over the
ground field. Via the quasi-classical limit ""as the motive of affine line
approaches to 1"" we obtain numerical DT-invariants which are closely related to
those introduced by Behrend. We study some properties of both motivic and
numerical DT-invariants including the wall-crossing formulas and integrality.
We discuss the relationship with the mathematical works (in the
non-triangulated case) of Joyce, Bridgeland and Toledano-Laredo, as well as
with works of physicists on Seiberg-Witten model (string junctions),
classification of N=2 supersymmetric theories (Cecotti-Vafa) and structure of
the moduli space of vector multiplets. Relating the theory of 3d Calabi-Yau
categories with distinguished set of generators (called cluster collection)
with the theory of quivers with potential we found the connection with cluster
transformations and cluster varieties (both classical and quantum).
","Maxim Kontsevich, Yan Soibelman",,Mathematics,Mathematics
2012,0811.2435,35,"Stability structures, motivic Donaldson-Thomas invariants and cluster
  transformations","  We define new invariants of 3d Calabi-Yau categories endowed with a stability
structure. Intuitively, they count the number of semistable objects with fixed
class in the K-theory of the category (""number of BPS states with given charge""
in physics language). Formally, our motivic DT-invariants are elements of
quantum tori over a version of the Grothendieck ring of varieties over the
ground field. Via the quasi-classical limit ""as the motive of affine line
approaches to 1"" we obtain numerical DT-invariants which are closely related to
those introduced by Behrend. We study some properties of both motivic and
numerical DT-invariants including the wall-crossing formulas and integrality.
We discuss the relationship with the mathematical works (in the
non-triangulated case) of Joyce, Bridgeland and Toledano-Laredo, as well as
with works of physicists on Seiberg-Witten model (string junctions),
classification of N=2 supersymmetric theories (Cecotti-Vafa) and structure of
the moduli space of vector multiplets. Relating the theory of 3d Calabi-Yau
categories with distinguished set of generators (called cluster collection)
with the theory of quivers with potential we found the connection with cluster
transformations and cluster varieties (both classical and quantum).
","Maxim Kontsevich, Yan Soibelman",,Mathematics,Mathematics
2013,0811.2435,40,"Stability structures, motivic Donaldson-Thomas invariants and cluster
  transformations","  We define new invariants of 3d Calabi-Yau categories endowed with a stability
structure. Intuitively, they count the number of semistable objects with fixed
class in the K-theory of the category (""number of BPS states with given charge""
in physics language). Formally, our motivic DT-invariants are elements of
quantum tori over a version of the Grothendieck ring of varieties over the
ground field. Via the quasi-classical limit ""as the motive of affine line
approaches to 1"" we obtain numerical DT-invariants which are closely related to
those introduced by Behrend. We study some properties of both motivic and
numerical DT-invariants including the wall-crossing formulas and integrality.
We discuss the relationship with the mathematical works (in the
non-triangulated case) of Joyce, Bridgeland and Toledano-Laredo, as well as
with works of physicists on Seiberg-Witten model (string junctions),
classification of N=2 supersymmetric theories (Cecotti-Vafa) and structure of
the moduli space of vector multiplets. Relating the theory of 3d Calabi-Yau
categories with distinguished set of generators (called cluster collection)
with the theory of quivers with potential we found the connection with cluster
transformations and cluster varieties (both classical and quantum).
","Maxim Kontsevich, Yan Soibelman",,Mathematics,Mathematics
2016,0811.2435,43,"Stability structures, motivic Donaldson-Thomas invariants and cluster
  transformations","  We define new invariants of 3d Calabi-Yau categories endowed with a stability
structure. Intuitively, they count the number of semistable objects with fixed
class in the K-theory of the category (""number of BPS states with given charge""
in physics language). Formally, our motivic DT-invariants are elements of
quantum tori over a version of the Grothendieck ring of varieties over the
ground field. Via the quasi-classical limit ""as the motive of affine line
approaches to 1"" we obtain numerical DT-invariants which are closely related to
those introduced by Behrend. We study some properties of both motivic and
numerical DT-invariants including the wall-crossing formulas and integrality.
We discuss the relationship with the mathematical works (in the
non-triangulated case) of Joyce, Bridgeland and Toledano-Laredo, as well as
with works of physicists on Seiberg-Witten model (string junctions),
classification of N=2 supersymmetric theories (Cecotti-Vafa) and structure of
the moduli space of vector multiplets. Relating the theory of 3d Calabi-Yau
categories with distinguished set of generators (called cluster collection)
with the theory of quivers with potential we found the connection with cluster
transformations and cluster varieties (both classical and quantum).
","Maxim Kontsevich, Yan Soibelman",,Mathematics,Mathematics
2011,1001.3404,38,Lecture Notes on Network Information Theory,"  These lecture notes have been converted to a book titled Network Information
Theory published recently by Cambridge University Press. This book provides a
significantly expanded exposition of the material in the lecture notes as well
as problems and bibliographic notes at the end of each chapter. The authors are
currently preparing a set of slides based on the book that will be posted in
the second half of 2012. More information about the book can be found at
http://www.cambridge.org/9781107008731/. The previous (and obsolete) version of
the lecture notes can be found at http://arxiv.org/abs/1001.3404v4/.
","Abbas El Gamal, Young-Han Kim",,Mathematics,"Mathematics,Computer Science"
2013,0812.5023,47,2-Kac-Moody algebras,"  We construct a 2-category associated with a Kac-Moody algebra and we study
its 2-representations. This generalizes earlier work with Chuang for type A. We
relate categorifications relying on K_0 properties and 2-representations.
",Raphael Rouquier,,Mathematics,Mathematics
2014,0812.5023,40,2-Kac-Moody algebras,"  We construct a 2-category associated with a Kac-Moody algebra and we study
its 2-representations. This generalizes earlier work with Chuang for type A. We
relate categorifications relying on K_0 properties and 2-representations.
",Raphael Rouquier,,Mathematics,Mathematics
2015,0812.5023,45,2-Kac-Moody algebras,"  We construct a 2-category associated with a Kac-Moody algebra and we study
its 2-representations. This generalizes earlier work with Chuang for type A. We
relate categorifications relying on K_0 properties and 2-representations.
",Raphael Rouquier,,Mathematics,Mathematics
2016,0812.5023,45,2-Kac-Moody algebras,"  We construct a 2-category associated with a Kac-Moody algebra and we study
its 2-representations. This generalizes earlier work with Chuang for type A. We
relate categorifications relying on K_0 properties and 2-representations.
",Raphael Rouquier,,Mathematics,Mathematics
2015,1011.3027,43,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Mathematics,"Mathematics,Statistics"
2017,1011.3027,52,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Mathematics,Mathematics
2018,1011.3027,56,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Mathematics,Mathematics
2019,1011.3027,58,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Mathematics,Mathematics
2020,1011.3027,11,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Mathematics,Mathematics
2017,1412.6980,48,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Mathematics,"Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1412.6980,122,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Mathematics,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2019,1412.6980,203,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Mathematics,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2020,1412.6980,45,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Mathematics,"Physics,Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2000,cs/0010035,14,"Proceedings of the Fourth International Workshop on Automated Debugging
  (AADEBUG 2000)","  Over the past decades automated debugging has seen major achievements.
However, as debugging is by necessity attached to particular programming
paradigms, the results are scattered. The aims of the workshop are to gather
common themes and solutions across programming communities, and to
cross-fertilize ideas. AADEBUG 2000 in Munich follows AADEBUG'93 in Linkoeping,
Sweden; AADEBUG'95 in Saint Malo, France; AADEBUG'97 in Linkoeping, Sweden.
",M. Ducasse (IRISA/INSA de Rennes),,Computer Science,Computer Science
2003,cs/0309027,22,"Proceedings of the Fifth International Workshop on Automated Debugging
  (AADEBUG 2003)","  Over the past decades automated debugging has seen major achievements.
However, as debugging is by necessity attached to particular programming
paradigms, the results are scattered. To alleviate this problem, the Automated
and Algorithmic Debugging workshop (AADEBUG for short) was organised in 1993 in
Link""oping (Sweden). As this workshop proved to be successful, subsequent
workshops have been organised in 1995 (Saint-Malo, France), 1997 (again in
Link""oping, Sweden) and 2000 (Munich, Germany). In 2003, the workshop is
organised in Ghent, Belgium, the proceedings of which you are reading right
now.
",Michiel Ronsse and Koen De Bosschere,,Computer Science,Computer Science
2004,math/0312397,16,"On Simple Characterisations of Sheffer psi- polynomials and Related
  Propositions of the Calculus of Sequences","  A calculus of sequences started in 1936 opened the way for future extensions
of umbral calculus in its finite operator form. Because of historically
established notation we call it the psi-calculus.It appears in parts to be
almost automatic extension of the standard classical finite operator calculus.
",A. K. Kwasniewski,"Bull. Soc. Sci. Lett. Lodz Ser. Rech. Deform. 52, Ser. Rech.
  Deform. 36 (2002) pp.45-65",Computer Science,"Mathematics,Computer Science"
2004,math/0402078,11,Towards psi-extension of Rota`s Finite Operator Calculus,"  A class of extended umbral calculi in operator form is presented. Extensions
of all basic theorems of classical Finite Operator Calculus are shown to hold.
The impossibility of straightforward extending of quantum q-plane formulation
of the q-umbral caculus to the general psi-calculus case is demonstrated.
",A. K. Kwasniewski,Reports on Mathematical Physics Vol. 48 No 3 (2001) : 305-342,Computer Science,Computer Science
2006,cs/0512078,11,"Graph-Cover Decoding and Finite-Length Analysis of Message-Passing
  Iterative Decoding of LDPC Codes","  The goal of the present paper is the derivation of a framework for the
finite-length analysis of message-passing iterative decoding of low-density
parity-check codes. To this end we introduce the concept of graph-cover
decoding. Whereas in maximum-likelihood decoding all codewords in a code are
competing to be the best explanation of the received vector, under graph-cover
decoding all codewords in all finite covers of a Tanner graph representation of
the code are competing to be the best explanation. We are interested in
graph-cover decoding because it is a theoretical tool that can be used to show
connections between linear programming decoding and message-passing iterative
decoding. Namely, on the one hand it turns out that graph-cover decoding is
essentially equivalent to linear programming decoding. On the other hand,
because iterative, locally operating decoding algorithms like message-passing
iterative decoding cannot distinguish the underlying Tanner graph from any
covering graph, graph-cover decoding can serve as a model to explain the
behavior of message-passing iterative decoding. Understanding the behavior of
graph-cover decoding is tantamount to understanding the so-called fundamental
polytope. Therefore, we give some characterizations of this polytope and
explain its relation to earlier concepts that were introduced to understand the
behavior of message-passing iterative decoding for finite-length codes.
",Pascal O. Vontobel and Ralf Koetter,,Computer Science,Computer Science
2011,cs/0512078,13,"Graph-Cover Decoding and Finite-Length Analysis of Message-Passing
  Iterative Decoding of LDPC Codes","  The goal of the present paper is the derivation of a framework for the
finite-length analysis of message-passing iterative decoding of low-density
parity-check codes. To this end we introduce the concept of graph-cover
decoding. Whereas in maximum-likelihood decoding all codewords in a code are
competing to be the best explanation of the received vector, under graph-cover
decoding all codewords in all finite covers of a Tanner graph representation of
the code are competing to be the best explanation. We are interested in
graph-cover decoding because it is a theoretical tool that can be used to show
connections between linear programming decoding and message-passing iterative
decoding. Namely, on the one hand it turns out that graph-cover decoding is
essentially equivalent to linear programming decoding. On the other hand,
because iterative, locally operating decoding algorithms like message-passing
iterative decoding cannot distinguish the underlying Tanner graph from any
covering graph, graph-cover decoding can serve as a model to explain the
behavior of message-passing iterative decoding. Understanding the behavior of
graph-cover decoding is tantamount to understanding the so-called fundamental
polytope. Therefore, we give some characterizations of this polytope and
explain its relation to earlier concepts that were introduced to understand the
behavior of message-passing iterative decoding for finite-length codes.
",Pascal O. Vontobel and Ralf Koetter,,Computer Science,Computer Science
2008,0801.3985,11,Cobweb posets - Recent Results,"  Cobweb posets uniquely represented by directed acyclic graphs are such a
generalization of the Fibonacci tree that allows joint combinatorial
interpretation for all of them under admissibility condition. This
interpretation was derived in the source papers ([6,7] and references therein
to the first author).[7,6,8] include natural enquires to be reported on here.
The purpose of this presentation is to report on the progress in solving
computational problems which are quite easily formulated for the new class of
directed acyclic graphs interpreted as Hasse diagrams. The problems posed there
and not yet all solved completely are of crucial importance for the vast class
of new partially ordered sets with joint combinatorial interpretation. These so
called cobweb posets - are relatives of Fibonacci tree and are labeled by
specific number sequences - natural numbers sequence and Fibonacci sequence
included. The cobweb posets might be identified with a chain of di-bicliques
i.e. by definition - a chain of complete bipartite one direction digraphs [6].
Any chain of relations is therefore obtainable from the cobweb poset chain of
complete relations via deleting arcs in di-bicliques of the complete relations
chain. In particular we response to one of those problems [1].
","A. Krzysztof Kwasniewski, M. Dziemianczuk","Adv. Stud. Contemp. Math. volume 16 (2), 2008 (April) pp. 197-218",Computer Science,Computer Science
2008,math/0512578,11,On cobweb posets and their combinatorially admissible sequences,"  The main purpose of this article is to pose three problems which are easy to
be formulated in an elementary way. These problems which are specifically
important also for the new class of partially ordered sets seem to be not yet
solved.
",A. K. Kwasniewski,"Adv. Studies Contemp. Math. Vol. 18 No 1, 2009 17-32",Computer Science,Computer Science
2009,0809.3554,12,"The Approximate Capacity of the Many-to-One and One-to-Many Gaussian
  Interference Channels","  Recently, Etkin, Tse, and Wang found the capacity region of the two-user
Gaussian interference channel to within one bit/s/Hz. A natural goal is to
apply this approach to the Gaussian interference channel with an arbitrary
number of users. We make progress towards this goal by finding the capacity
region of the many-to-one and one-to-many Gaussian interference channels to
within a constant number of bits. The result makes use of a deterministic model
to provide insight into the Gaussian channel. The deterministic model makes
explicit the dimension of signal scale. A central theme emerges: the use of
lattice codes for alignment of interfering signals on the signal scale.
","Guy Bresler, Abhay Parekh, and David Tse",,Computer Science,Computer Science
2010,1001.3404,17,Lecture Notes on Network Information Theory,"  These lecture notes have been converted to a book titled Network Information
Theory published recently by Cambridge University Press. This book provides a
significantly expanded exposition of the material in the lecture notes as well
as problems and bibliographic notes at the end of each chapter. The authors are
currently preparing a set of slides based on the book that will be posted in
the second half of 2012. More information about the book can be found at
http://www.cambridge.org/9781107008731/. The previous (and obsolete) version of
the lecture notes can be found at http://arxiv.org/abs/1001.3404v4/.
","Abbas El Gamal, Young-Han Kim",,Computer Science,Computer Science
2011,1001.3404,38,Lecture Notes on Network Information Theory,"  These lecture notes have been converted to a book titled Network Information
Theory published recently by Cambridge University Press. This book provides a
significantly expanded exposition of the material in the lecture notes as well
as problems and bibliographic notes at the end of each chapter. The authors are
currently preparing a set of slides based on the book that will be posted in
the second half of 2012. More information about the book can be found at
http://www.cambridge.org/9781107008731/. The previous (and obsolete) version of
the lecture notes can be found at http://arxiv.org/abs/1001.3404v4/.
","Abbas El Gamal, Young-Han Kim",,Computer Science,"Mathematics,Computer Science"
2012,1001.3404,28,Lecture Notes on Network Information Theory,"  These lecture notes have been converted to a book titled Network Information
Theory published recently by Cambridge University Press. This book provides a
significantly expanded exposition of the material in the lecture notes as well
as problems and bibliographic notes at the end of each chapter. The authors are
currently preparing a set of slides based on the book that will be posted in
the second half of 2012. More information about the book can be found at
http://www.cambridge.org/9781107008731/. The previous (and obsolete) version of
the lecture notes can be found at http://arxiv.org/abs/1001.3404v4/.
","Abbas El Gamal, Young-Han Kim",,Computer Science,Computer Science
2010,0906.5394,14,Wireless Network Information Flow: A Deterministic Approach,"  In a wireless network with a single source and a single destination and an
arbitrary number of relay nodes, what is the maximum rate of information flow
achievable? We make progress on this long standing problem through a two-step
approach. First we propose a deterministic channel model which captures the key
wireless properties of signal strength, broadcast and superposition. We obtain
an exact characterization of the capacity of a network with nodes connected by
such deterministic channels. This result is a natural generalization of the
celebrated max-flow min-cut theorem for wired networks. Second, we use the
insights obtained from the deterministic analysis to design a new
quantize-map-and-forward scheme for Gaussian networks. In this scheme, each
relay quantizes the received signal at the noise level and maps it to a random
Gaussian codeword for forwarding, and the final destination decodes the
source's message based on the received signal. We show that, in contrast to
existing schemes, this scheme can achieve the cut-set upper bound to within a
gap which is independent of the channel parameters. In the case of the relay
channel with a single relay as well as the two-relay Gaussian diamond network,
the gap is 1 bit/s/Hz. Moreover, the scheme is universal in the sense that the
relays need no knowledge of the values of the channel parameters to
(approximately) achieve the rate supportable by the network. We also present
extensions of the results to multicast networks, half-duplex networks and
ergodic networks.
","Salman Avestimehr, Suhas Diggavi, and David Tse",,Computer Science,Computer Science
2010,quant-ph/0512258,12,Security of Quantum Key Distribution,"  We propose various new techniques in quantum information theory, including a
de Finetti style representation theorem for finite symmetric quantum states. As
an application, we give a proof for the security of quantum key distribution
which applies to arbitrary protocols.
",Renato Renner,,Computer Science,Computer Science
2011,0908.2282,14,"Real Interference Alignment: Exploiting the Potential of Single Antenna
  Systems","  In this paper, the available spatial Degrees-Of-Freedoms (DOF) in single
antenna systems is exploited. A new coding scheme is proposed in which several
data streams having fractional multiplexing gains are sent by transmitters and
interfering streams are aligned at receivers. Viewed as a field over rational
numbers, a received signal has infinite fractional DOFs, allowing simultaneous
interference alignment of any finite number of signals at any finite number of
receivers. The coding scheme is backed up by a recent result in the field of
Diophantine approximation, which states that the convergence part of the
Khintchine-Groshev theorem holds for points on non-degenerate manifolds. The
proposed coding scheme is proved to be optimal for three communication
channels, namely the Gaussian Interference Channel (GIC), the uplink channel in
cellular systems, and the $X$ channel. It is proved that the total DOF of the
$K$-user GIC is $\frac{K}{2}$ almost surely, i.e. each user enjoys half of its
maximum DOF. Having $K$ cells and $M$ users within each cell in a cellular
system, the total DOF of the uplink channel is proved to be $\frac{KM}{M+1}$.
Finally, the total DOF of the $X$ channel with $K$ transmitters and $M$
receivers is shown to be $\frac{KM}{K+M-1}$.
","Abolfazl Seyed Motahari, Shahab Oveis Gharan, Mohammad-Ali Maddah-Ali,
  and Amir Keyvan Khandani",,Computer Science,Computer Science
2012,1106.1445,18,From Classical to Quantum Shannon Theory,"  The aim of this book is to develop ""from the ground up"" many of the major,
exciting, pre- and post-millenium developments in the general area of study
known as quantum Shannon theory. As such, we spend a significant amount of time
on quantum mechanics for quantum information theory (Part II), we give a
careful study of the important unit protocols of teleportation, super-dense
coding, and entanglement distribution (Part III), and we develop many of the
tools necessary for understanding information transmission or compression (Part
IV). Parts V and VI are the culmination of this book, where all of the tools
developed come into play for understanding many of the important results in
quantum Shannon theory.
",Mark M. Wilde,,Computer Science,Computer Science
2012,1112.0708,14,"Information-Theoretically Optimal Compressed Sensing via Spatial
  Coupling and Approximate Message Passing","  We study the compressed sensing reconstruction problem for a broad class of
random, band-diagonal sensing matrices. This construction is inspired by the
idea of spatial coupling in coding theory. As demonstrated heuristically and
numerically by Krzakala et al. \cite{KrzakalaEtAl}, message passing algorithms
can effectively solve the reconstruction problem for spatially coupled
measurements with undersampling rates close to the fraction of non-zero
coordinates.
  We use an approximate message passing (AMP) algorithm and analyze it through
the state evolution method. We give a rigorous proof that this approach is
successful as soon as the undersampling rate $\delta$ exceeds the (upper)
R\'enyi information dimension of the signal, $\uRenyi(p_X)$. More precisely,
for a sequence of signals of diverging dimension $n$ whose empirical
distribution converges to $p_X$, reconstruction is with high probability
successful from $\uRenyi(p_X)\, n+o(n)$ measurements taken according to a band
diagonal matrix.
  For sparse signals, i.e., sequences of dimension $n$ and $k(n)$ non-zero
entries, this implies reconstruction from $k(n)+o(n)$ measurements. For
`discrete' signals, i.e., signals whose coordinates take a fixed finite set of
values, this implies reconstruction from $o(n)$ measurements. The result is
robust with respect to noise, does not apply uniquely to random signals, but
requires the knowledge of the empirical distribution of the signal $p_X$.
","David L. Donoho, Adel Javanmard and Andrea Montanari",,Computer Science,Computer Science
2013,1207.0580,61,"Improving neural networks by preventing co-adaptation of feature
  detectors","  When a large feedforward neural network is trained on a small training set,
it typically performs poorly on held-out test data. This ""overfitting"" is
greatly reduced by randomly omitting half of the feature detectors on each
training case. This prevents complex co-adaptations in which a feature detector
is only helpful in the context of several other specific feature detectors.
Instead, each neuron learns to detect a feature that is generally helpful for
producing the correct answer given the combinatorially large variety of
internal contexts in which it must operate. Random ""dropout"" gives big
improvements on many benchmark tasks and sets new records for speech and object
recognition.
","Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya
  Sutskever, Ruslan R. Salakhutdinov",,Computer Science,"Computer Science,Statistics"
2014,1207.0580,85,"Improving neural networks by preventing co-adaptation of feature
  detectors","  When a large feedforward neural network is trained on a small training set,
it typically performs poorly on held-out test data. This ""overfitting"" is
greatly reduced by randomly omitting half of the feature detectors on each
training case. This prevents complex co-adaptations in which a feature detector
is only helpful in the context of several other specific feature detectors.
Instead, each neuron learns to detect a feature that is generally helpful for
producing the correct answer given the combinatorially large variety of
internal contexts in which it must operate. Random ""dropout"" gives big
improvements on many benchmark tasks and sets new records for speech and object
recognition.
","Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya
  Sutskever, Ruslan R. Salakhutdinov",,Computer Science,"Computer Science,Statistics"
2013,0907.3666,23,Various thresholds for $\ell_1$-optimization in compressed sensing,"  Recently, \cite{CRT,DonohoPol} theoretically analyzed the success of a
polynomial $\ell_1$-optimization algorithm in solving an under-determined
system of linear equations. In a large dimensional and statistical context
\cite{CRT,DonohoPol} proved that if the number of equations (measurements in
the compressed sensing terminology) in the system is proportional to the length
of the unknown vector then there is a sparsity (number of non-zero elements of
the unknown vector) also proportional to the length of the unknown vector such
that $\ell_1$-optimization succeeds in solving the system. In this paper, we
provide an alternative performance analysis of $\ell_1$-optimization and obtain
the proportionality constants that in certain cases match or improve on the
best currently known ones from \cite{DonohoPol,DT}.
",Mihailo Stojnic,,Computer Science,Computer Science
2013,1011.3027,20,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Computer Science,"Computer Science,Statistics"
2014,1408.5093,49,Caffe: Convolutional Architecture for Fast Feature Embedding,"  Caffe provides multimedia scientists and practitioners with a clean and
modifiable framework for state-of-the-art deep learning algorithms and a
collection of reference models. The framework is a BSD-licensed C++ library
with Python and MATLAB bindings for training and deploying general-purpose
convolutional neural networks and other deep models efficiently on commodity
architectures. Caffe fits industry and internet-scale media needs by CUDA GPU
computation, processing over 40 million images a day on a single K40 or Titan
GPU ($\approx$ 2.5 ms per image). By separating model representation from
actual implementation, Caffe allows experimentation and seamless switching
among platforms for ease of development and deployment from prototyping
machines to cloud environments. Caffe is maintained and developed by the
Berkeley Vision and Learning Center (BVLC) with the help of an active community
of contributors on GitHub. It powers ongoing research projects, large-scale
industrial applications, and startup prototypes in vision, speech, and
multimedia.
","Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan
  Long, Ross Girshick, Sergio Guadarrama, Trevor Darrell",,Computer Science,Computer Science
2015,1408.5093,219,Caffe: Convolutional Architecture for Fast Feature Embedding,"  Caffe provides multimedia scientists and practitioners with a clean and
modifiable framework for state-of-the-art deep learning algorithms and a
collection of reference models. The framework is a BSD-licensed C++ library
with Python and MATLAB bindings for training and deploying general-purpose
convolutional neural networks and other deep models efficiently on commodity
architectures. Caffe fits industry and internet-scale media needs by CUDA GPU
computation, processing over 40 million images a day on a single K40 or Titan
GPU ($\approx$ 2.5 ms per image). By separating model representation from
actual implementation, Caffe allows experimentation and seamless switching
among platforms for ease of development and deployment from prototyping
machines to cloud environments. Caffe is maintained and developed by the
Berkeley Vision and Learning Center (BVLC) with the help of an active community
of contributors on GitHub. It powers ongoing research projects, large-scale
industrial applications, and startup prototypes in vision, speech, and
multimedia.
","Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan
  Long, Ross Girshick, Sergio Guadarrama, Trevor Darrell",,Computer Science,Computer Science
2014,1312.6229,48,"OverFeat: Integrated Recognition, Localization and Detection using
  Convolutional Networks","  We present an integrated framework for using Convolutional Networks for
classification, localization and detection. We show how a multiscale and
sliding window approach can be efficiently implemented within a ConvNet. We
also introduce a novel deep learning approach to localization by learning to
predict object boundaries. Bounding boxes are then accumulated rather than
suppressed in order to increase detection confidence. We show that different
tasks can be learned simultaneously using a single shared network. This
integrated framework is the winner of the localization task of the ImageNet
Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very
competitive results for the detection and classifications tasks. In
post-competition work, we establish a new state of the art for the detection
task. Finally, we release a feature extractor from our best model called
OverFeat.
","Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob
  Fergus, Yann LeCun",,Computer Science,Computer Science
2015,1409.1556,225,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Computer Science,Computer Science
2016,1409.1556,642,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Computer Science,"Computer Science,Quantitative Biology"
2017,1409.1556,1171,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Computer Science,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1409.1556,1899,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Computer Science,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2019,1409.1556,2152,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Computer Science,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2020,1409.1556,273,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Computer Science,"Computer Science,Electrical Engineering and Systems Science"
2015,1409.4842,179,Going Deeper with Convolutions,"  We propose a deep convolutional neural network architecture codenamed
""Inception"", which was responsible for setting the new state of the art for
classification and detection in the ImageNet Large-Scale Visual Recognition
Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the
improved utilization of the computing resources inside the network. This was
achieved by a carefully crafted design that allows for increasing the depth and
width of the network while keeping the computational budget constant. To
optimize quality, the architectural decisions were based on the Hebbian
principle and the intuition of multi-scale processing. One particular
incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22
layers deep network, the quality of which is assessed in the context of
classification and detection.
","Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
  Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke and Andrew Rabinovich",,Computer Science,Computer Science
2016,1412.6980,456,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Computer Science,"Computer Science,Quantitative Biology,Statistics"
2017,1412.6980,1487,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Computer Science,"Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1412.6980,2846,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Computer Science,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2019,1412.6980,4162,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Computer Science,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2020,1412.6980,617,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Computer Science,"Physics,Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2016,1512.03385,383,Deep Residual Learning for Image Recognition,"  Deeper neural networks are more difficult to train. We present a residual
learning framework to ease the training of networks that are substantially
deeper than those used previously. We explicitly reformulate the layers as
learning residual functions with reference to the layer inputs, instead of
learning unreferenced functions. We provide comprehensive empirical evidence
showing that these residual networks are easier to optimize, and can gain
accuracy from considerably increased depth. On the ImageNet dataset we evaluate
residual nets with a depth of up to 152 layers---8x deeper than VGG nets but
still having lower complexity. An ensemble of these residual nets achieves
3.57% error on the ImageNet test set. This result won the 1st place on the
ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100
and 1000 layers.
  The depth of representations is of central importance for many visual
recognition tasks. Solely due to our extremely deep representations, we obtain
a 28% relative improvement on the COCO object detection dataset. Deep residual
nets are foundations of our submissions to ILSVRC & COCO 2015 competitions,
where we also won the 1st places on the tasks of ImageNet detection, ImageNet
localization, COCO detection, and COCO segmentation.
","Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun",,Computer Science,"Computer Science,Statistics"
2017,1409.0473,414,Neural Machine Translation by Jointly Learning to Align and Translate,"  Neural machine translation is a recently proposed approach to machine
translation. Unlike the traditional statistical machine translation, the neural
machine translation aims at building a single neural network that can be
jointly tuned to maximize the translation performance. The models proposed
recently for neural machine translation often belong to a family of
encoder-decoders and consists of an encoder that encodes a source sentence into
a fixed-length vector from which a decoder generates a translation. In this
paper, we conjecture that the use of a fixed-length vector is a bottleneck in
improving the performance of this basic encoder-decoder architecture, and
propose to extend this by allowing a model to automatically (soft-)search for
parts of a source sentence that are relevant to predicting a target word,
without having to form these parts as a hard segment explicitly. With this new
approach, we achieve a translation performance comparable to the existing
state-of-the-art phrase-based system on the task of English-to-French
translation. Furthermore, qualitative analysis reveals that the
(soft-)alignments found by the model agree well with our intuition.
",Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio,,Computer Science,Computer Science
2018,1409.0473,735,Neural Machine Translation by Jointly Learning to Align and Translate,"  Neural machine translation is a recently proposed approach to machine
translation. Unlike the traditional statistical machine translation, the neural
machine translation aims at building a single neural network that can be
jointly tuned to maximize the translation performance. The models proposed
recently for neural machine translation often belong to a family of
encoder-decoders and consists of an encoder that encodes a source sentence into
a fixed-length vector from which a decoder generates a translation. In this
paper, we conjecture that the use of a fixed-length vector is a bottleneck in
improving the performance of this basic encoder-decoder architecture, and
propose to extend this by allowing a model to automatically (soft-)search for
parts of a source sentence that are relevant to predicting a target word,
without having to form these parts as a hard segment explicitly. With this new
approach, we achieve a translation performance comparable to the existing
state-of-the-art phrase-based system on the task of English-to-French
translation. Furthermore, qualitative analysis reveals that the
(soft-)alignments found by the model agree well with our intuition.
",Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio,,Computer Science,Computer Science
2019,1810.04805,1288,"BERT: Pre-training of Deep Bidirectional Transformers for Language
  Understanding","  We introduce a new language representation model called BERT, which stands
for Bidirectional Encoder Representations from Transformers. Unlike recent
language representation models, BERT is designed to pre-train deep
bidirectional representations from unlabeled text by jointly conditioning on
both left and right context in all layers. As a result, the pre-trained BERT
model can be fine-tuned with just one additional output layer to create
state-of-the-art models for a wide range of tasks, such as question answering
and language inference, without substantial task-specific architecture
modifications.
  BERT is conceptually simple and empirically powerful. It obtains new
state-of-the-art results on eleven natural language processing tasks, including
pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI
accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering
Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1
(5.1 point absolute improvement).
","Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova",,Computer Science,Computer Science
2020,1810.04805,190,"BERT: Pre-training of Deep Bidirectional Transformers for Language
  Understanding","  We introduce a new language representation model called BERT, which stands
for Bidirectional Encoder Representations from Transformers. Unlike recent
language representation models, BERT is designed to pre-train deep
bidirectional representations from unlabeled text by jointly conditioning on
both left and right context in all layers. As a result, the pre-trained BERT
model can be fine-tuned with just one additional output layer to create
state-of-the-art models for a wide range of tasks, such as question answering
and language inference, without substantial task-specific architecture
modifications.
  BERT is conceptually simple and empirically powerful. It obtains new
state-of-the-art results on eleven natural language processing tasks, including
pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI
accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering
Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1
(5.1 point absolute improvement).
","Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova",,Computer Science,Computer Science
2015,0904.0575,12,Aging as a consequence of misrepair -- a novel theory of aging,"  It is now increasingly realized that the underlying mechanism which governs
aging (ageing) is a complex interplay of genetic regulation and
damage-accumulation. ""Aging as a result of accumulation of 'faults' on cellular
and molecular levels"", has been proposed in the damage (fault)-accumulation
theory. However, this theory fails to explain some aging phenotypes such as
fibrosis and premature aging, since terms such as 'damage' and 'fault' are not
specified. Therefore we introduce some crucial modifications of this theory and
arrive at a novel theory: aging of the body is the result of accumulation of
Misrepair of tissue. It emphasizes: a) it is Misrepair, not the original
damage, that accumulates and leads to aging; and b) aging can occur at
different levels, however aging of the body takes place necessarily on the
tissue level, but not requiring the aging of cells/molecules. The
Misrepair-accumulation theory introduced in the present paper unifies the
understanding of the roles of environmental damage, repair, gene regulation,
and multicellular structure in the aging process. This theory gives
explanations for the aging phenotypes, premature aging, the difference of
longevity in different species, and it is consistent with the physical view on
complex systems.
","Jicun Wang (CUH), Thomas Michelitsch (IJLRA), Arne Wunderlin, Ravi
  Mahadeva (CUH)",,Quantitative Biology,Quantitative Biology
2016,1412.6980,13,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Biology,"Computer Science,Quantitative Biology,Statistics"
2017,1412.6980,38,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Biology,"Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1412.6980,51,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Biology,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2019,1412.6980,73,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Biology,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2020,1412.6980,15,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Biology,"Physics,Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2016,1409.1556,12,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Quantitative Biology,"Computer Science,Quantitative Biology"
2017,1409.1556,21,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Quantitative Biology,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1409.1556,29,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Quantitative Biology,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2019,1409.1556,33,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Quantitative Biology,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2017,1603.04467,17,"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed
  Systems","  TensorFlow is an interface for expressing machine learning algorithms, and an
implementation for executing such algorithms. A computation expressed using
TensorFlow can be executed with little or no change on a wide variety of
heterogeneous systems, ranging from mobile devices such as phones and tablets
up to large-scale distributed systems of hundreds of machines and thousands of
computational devices such as GPU cards. The system is flexible and can be used
to express a wide variety of algorithms, including training and inference
algorithms for deep neural network models, and it has been used for conducting
research and for deploying machine learning systems into production across more
than a dozen areas of computer science and other fields, including speech
recognition, computer vision, robotics, information retrieval, natural language
processing, geographic information extraction, and computational drug
discovery. This paper describes the TensorFlow interface and an implementation
of that interface that we have built at Google. The TensorFlow API and a
reference implementation were released as an open-source package under the
Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.
","Mart\'in Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng
  Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin,
  Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
  Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
  Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah,
  Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar,
  Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol
  Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang
  Zheng",,Quantitative Biology,Quantitative Biology
2018,1312.6114,14,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Quantitative Biology,"Quantitative Biology,Statistics"
2019,1312.6114,28,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Quantitative Biology,"Quantitative Biology,Statistics"
2011,0904.3523,11,Structured Variable Selection with Sparsity-Inducing Norms,"  We consider the empirical risk minimization problem for linear supervised
learning, with regularization by structured sparsity-inducing norms. These are
defined as sums of Euclidean norms on certain subsets of variables, extending
the usual $\ell_1$-norm and the group $\ell_1$-norm by allowing the subsets to
overlap. This leads to a specific set of allowed nonzero patterns for the
solutions of such problems. We first explore the relationship between the
groups defining the norm and the resulting nonzero patterns, providing both
forward and backward algorithms to go back and forth from groups to patterns.
This allows the design of norms adapted to specific prior knowledge expressed
in terms of nonzero patterns. We also present an efficient active set
algorithm, and analyze the consistency of variable selection for least-squares
linear regression in low and high-dimensional settings.
","Rodolphe Jenatton (INRIA Rocquencourt), Jean-Yves Audibert (INRIA
  Rocquencourt), Francis Bach (INRIA Rocquencourt)",Journal of Machine Learning Research 12 (2011) 2777-2824,Statistics,Statistics
2013,1011.3027,27,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Statistics,"Computer Science,Statistics"
2014,1011.3027,20,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Statistics,Statistics
2015,1011.3027,47,Introduction to the non-asymptotic analysis of random matrices,"  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
",Roman Vershynin,"Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012",Statistics,"Mathematics,Statistics"
2013,1207.0580,27,"Improving neural networks by preventing co-adaptation of feature
  detectors","  When a large feedforward neural network is trained on a small training set,
it typically performs poorly on held-out test data. This ""overfitting"" is
greatly reduced by randomly omitting half of the feature detectors on each
training case. This prevents complex co-adaptations in which a feature detector
is only helpful in the context of several other specific feature detectors.
Instead, each neuron learns to detect a feature that is generally helpful for
producing the correct answer given the combinatorially large variety of
internal contexts in which it must operate. Random ""dropout"" gives big
improvements on many benchmark tasks and sets new records for speech and object
recognition.
","Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya
  Sutskever, Ruslan R. Salakhutdinov",,Statistics,"Computer Science,Statistics"
2014,1207.0580,33,"Improving neural networks by preventing co-adaptation of feature
  detectors","  When a large feedforward neural network is trained on a small training set,
it typically performs poorly on held-out test data. This ""overfitting"" is
greatly reduced by randomly omitting half of the feature detectors on each
training case. This prevents complex co-adaptations in which a feature detector
is only helpful in the context of several other specific feature detectors.
Instead, each neuron learns to detect a feature that is generally helpful for
producing the correct answer given the combinatorially large variety of
internal contexts in which it must operate. Random ""dropout"" gives big
improvements on many benchmark tasks and sets new records for speech and object
recognition.
","Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya
  Sutskever, Ruslan R. Salakhutdinov",,Statistics,"Computer Science,Statistics"
2015,1207.0580,37,"Improving neural networks by preventing co-adaptation of feature
  detectors","  When a large feedforward neural network is trained on a small training set,
it typically performs poorly on held-out test data. This ""overfitting"" is
greatly reduced by randomly omitting half of the feature detectors on each
training case. This prevents complex co-adaptations in which a feature detector
is only helpful in the context of several other specific feature detectors.
Instead, each neuron learns to detect a feature that is generally helpful for
producing the correct answer given the combinatorially large variety of
internal contexts in which it must operate. Random ""dropout"" gives big
improvements on many benchmark tasks and sets new records for speech and object
recognition.
","Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya
  Sutskever, Ruslan R. Salakhutdinov",,Statistics,Statistics
2013,1210.7559,15,Tensor decompositions for learning latent variable models,"  This work considers a computationally and statistically efficient parameter
estimation method for a wide class of latent variable models---including
Gaussian mixture models, hidden Markov models, and latent Dirichlet
allocation---which exploits a certain tensor structure in their low-order
observable moments (typically, of second- and third-order). Specifically,
parameter estimation is reduced to the problem of extracting a certain
(orthogonal) decomposition of a symmetric tensor derived from the moments; this
decomposition can be viewed as a natural generalization of the singular value
decomposition for matrices. Although tensor decompositions are generally
intractable to compute, the decomposition of these specially structured tensors
can be efficiently obtained by a variety of approaches, including power
iterations and maximization approaches (similar to the case of matrices). A
detailed analysis of a robust tensor power method is provided, establishing an
analogue of Wedin's perturbation theorem for the singular vectors of matrices.
This implies a robust and computationally tractable estimation approach for
several popular latent variable models.
","Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade and
  Matus Telgarsky","Journal of Machine Learning Research, 15(Aug):2773-2832, 2014",Statistics,Statistics
2014,1210.7559,15,Tensor decompositions for learning latent variable models,"  This work considers a computationally and statistically efficient parameter
estimation method for a wide class of latent variable models---including
Gaussian mixture models, hidden Markov models, and latent Dirichlet
allocation---which exploits a certain tensor structure in their low-order
observable moments (typically, of second- and third-order). Specifically,
parameter estimation is reduced to the problem of extracting a certain
(orthogonal) decomposition of a symmetric tensor derived from the moments; this
decomposition can be viewed as a natural generalization of the singular value
decomposition for matrices. Although tensor decompositions are generally
intractable to compute, the decomposition of these specially structured tensors
can be efficiently obtained by a variety of approaches, including power
iterations and maximization approaches (similar to the case of matrices). A
detailed analysis of a robust tensor power method is provided, establishing an
analogue of Wedin's perturbation theorem for the singular vectors of matrices.
This implies a robust and computationally tractable estimation approach for
several popular latent variable models.
","Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade and
  Matus Telgarsky","Journal of Machine Learning Research, 15(Aug):2773-2832, 2014",Statistics,Statistics
2015,1412.6980,32,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Statistics,Statistics
2016,1412.6980,110,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Statistics,"Computer Science,Quantitative Biology,Statistics"
2017,1412.6980,449,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Statistics,"Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1412.6980,1056,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Statistics,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2019,1412.6980,1555,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Statistics,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2020,1412.6980,277,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Statistics,"Physics,Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2016,1312.6114,56,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Statistics,Statistics
2017,1312.6114,151,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Statistics,Statistics
2018,1312.6114,378,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Statistics,"Quantitative Biology,Statistics"
2019,1312.6114,620,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Statistics,"Quantitative Biology,Statistics"
2020,1312.6114,91,Auto-Encoding Variational Bayes,"  How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.
","Diederik P Kingma, Max Welling",,Statistics,Statistics
2016,1512.03385,53,Deep Residual Learning for Image Recognition,"  Deeper neural networks are more difficult to train. We present a residual
learning framework to ease the training of networks that are substantially
deeper than those used previously. We explicitly reformulate the layers as
learning residual functions with reference to the layer inputs, instead of
learning unreferenced functions. We provide comprehensive empirical evidence
showing that these residual networks are easier to optimize, and can gain
accuracy from considerably increased depth. On the ImageNet dataset we evaluate
residual nets with a depth of up to 152 layers---8x deeper than VGG nets but
still having lower complexity. An ensemble of these residual nets achieves
3.57% error on the ImageNet test set. This result won the 1st place on the
ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100
and 1000 layers.
  The depth of representations is of central importance for many visual
recognition tasks. Solely due to our extremely deep representations, we obtain
a 28% relative improvement on the COCO object detection dataset. Deep residual
nets are foundations of our submissions to ILSVRC & COCO 2015 competitions,
where we also won the 1st places on the tasks of ImageNet detection, ImageNet
localization, COCO detection, and COCO segmentation.
","Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun",,Statistics,"Computer Science,Statistics"
2017,1409.1556,137,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Statistics,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1409.1556,403,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Statistics,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2019,1409.1556,509,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Statistics,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2020,1412.6572,77,Explaining and Harnessing Adversarial Examples,"  Several machine learning models, including neural networks, consistently
misclassify adversarial examples---inputs formed by applying small but
intentionally worst-case perturbations to examples from the dataset, such that
the perturbed input results in the model outputting an incorrect answer with
high confidence. Early attempts at explaining this phenomenon focused on
nonlinearity and overfitting. We argue instead that the primary cause of neural
networks' vulnerability to adversarial perturbation is their linear nature.
This explanation is supported by new quantitative results while giving the
first explanation of the most intriguing fact about them: their generalization
across architectures and training sets. Moreover, this view yields a simple and
fast method of generating adversarial examples. Using this approach to provide
examples for adversarial training, we reduce the test set error of a maxout
network on the MNIST dataset.
","Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy",,Statistics,Statistics
2018,1412.6980,18,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Finance,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2019,1412.6980,33,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Quantitative Finance,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2017,1412.6980,35,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Electrical Engineering and Systems Science,"Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1412.6980,212,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Electrical Engineering and Systems Science,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2019,1412.6980,797,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Electrical Engineering and Systems Science,"Mathematics,Computer Science,Quantitative Biology,Statistics,Quantitative Finance,Electrical Engineering and Systems Science"
2020,1412.6980,179,Adam: A Method for Stochastic Optimization,"  We introduce Adam, an algorithm for first-order gradient-based optimization
of stochastic objective functions, based on adaptive estimates of lower-order
moments. The method is straightforward to implement, is computationally
efficient, has little memory requirements, is invariant to diagonal rescaling
of the gradients, and is well suited for problems that are large in terms of
data and/or parameters. The method is also appropriate for non-stationary
objectives and problems with very noisy and/or sparse gradients. The
hyper-parameters have intuitive interpretations and typically require little
tuning. Some connections to related algorithms, on which Adam was inspired, are
discussed. We also analyze the theoretical convergence properties of the
algorithm and provide a regret bound on the convergence rate that is comparable
to the best known results under the online convex optimization framework.
Empirical results demonstrate that Adam works well in practice and compares
favorably to other stochastic optimization methods. Finally, we discuss AdaMax,
a variant of Adam based on the infinity norm.
",Diederik P. Kingma and Jimmy Ba,,Electrical Engineering and Systems Science,"Physics,Mathematics,Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2017,1609.03499,17,WaveNet: A Generative Model for Raw Audio,"  This paper introduces WaveNet, a deep neural network for generating raw audio
waveforms. The model is fully probabilistic and autoregressive, with the
predictive distribution for each audio sample conditioned on all previous ones;
nonetheless we show that it can be efficiently trained on data with tens of
thousands of samples per second of audio. When applied to text-to-speech, it
yields state-of-the-art performance, with human listeners rating it as
significantly more natural sounding than the best parametric and concatenative
systems for both English and Mandarin. A single WaveNet can capture the
characteristics of many different speakers with equal fidelity, and can switch
between them by conditioning on the speaker identity. When trained to model
music, we find that it generates novel and often highly realistic musical
fragments. We also show that it can be employed as a discriminative model,
returning promising results for phoneme recognition.
","Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
  Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu",,Electrical Engineering and Systems Science,Electrical Engineering and Systems Science
2018,1609.03499,92,WaveNet: A Generative Model for Raw Audio,"  This paper introduces WaveNet, a deep neural network for generating raw audio
waveforms. The model is fully probabilistic and autoregressive, with the
predictive distribution for each audio sample conditioned on all previous ones;
nonetheless we show that it can be efficiently trained on data with tens of
thousands of samples per second of audio. When applied to text-to-speech, it
yields state-of-the-art performance, with human listeners rating it as
significantly more natural sounding than the best parametric and concatenative
systems for both English and Mandarin. A single WaveNet can capture the
characteristics of many different speakers with equal fidelity, and can switch
between them by conditioning on the speaker identity. When trained to model
music, we find that it generates novel and often highly realistic musical
fragments. We also show that it can be employed as a discriminative model,
returning promising results for phoneme recognition.
","Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
  Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu",,Electrical Engineering and Systems Science,Electrical Engineering and Systems Science
2017,1409.1556,12,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Electrical Engineering and Systems Science,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2018,1409.1556,91,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Electrical Engineering and Systems Science,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2019,1409.1556,391,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Electrical Engineering and Systems Science,"Computer Science,Quantitative Biology,Statistics,Electrical Engineering and Systems Science"
2020,1409.1556,76,Very Deep Convolutional Networks for Large-Scale Image Recognition,"  In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.
","Karen Simonyan, Andrew Zisserman",,Electrical Engineering and Systems Science,"Computer Science,Electrical Engineering and Systems Science"
2019,1502.03167,224,"Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift","  Training Deep Neural Networks is complicated by the fact that the
distribution of each layer's inputs changes during training, as the parameters
of the previous layers change. This slows down the training by requiring lower
learning rates and careful parameter initialization, and makes it notoriously
hard to train models with saturating nonlinearities. We refer to this
phenomenon as internal covariate shift, and address the problem by normalizing
layer inputs. Our method draws its strength from making normalization a part of
the model architecture and performing the normalization for each training
mini-batch. Batch Normalization allows us to use much higher learning rates and
be less careful about initialization. It also acts as a regularizer, in some
cases eliminating the need for Dropout. Applied to a state-of-the-art image
classification model, Batch Normalization achieves the same accuracy with 14
times fewer training steps, and beats the original model by a significant
margin. Using an ensemble of batch-normalized networks, we improve upon the
best published result on ImageNet classification: reaching 4.9% top-5
validation error (and 4.8% test error), exceeding the accuracy of human raters.
","Sergey Ioffe, Christian Szegedy",,Electrical Engineering and Systems Science,Electrical Engineering and Systems Science
2020,1502.03167,48,"Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift","  Training Deep Neural Networks is complicated by the fact that the
distribution of each layer's inputs changes during training, as the parameters
of the previous layers change. This slows down the training by requiring lower
learning rates and careful parameter initialization, and makes it notoriously
hard to train models with saturating nonlinearities. We refer to this
phenomenon as internal covariate shift, and address the problem by normalizing
layer inputs. Our method draws its strength from making normalization a part of
the model architecture and performing the normalization for each training
mini-batch. Batch Normalization allows us to use much higher learning rates and
be less careful about initialization. It also acts as a regularizer, in some
cases eliminating the need for Dropout. Applied to a state-of-the-art image
classification model, Batch Normalization achieves the same accuracy with 14
times fewer training steps, and beats the original model by a significant
margin. Using an ensemble of batch-normalized networks, we improve upon the
best published result on ImageNet classification: reaching 4.9% top-5
validation error (and 4.8% test error), exceeding the accuracy of human raters.
","Sergey Ioffe, Christian Szegedy",,Electrical Engineering and Systems Science,Electrical Engineering and Systems Science
